{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\norouzin\\Desktop\\JointLearning\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from config import DEVICE, SEED, MODEL_CONFIG, TRAINING_CONFIG, DATASET_CONFIG\n",
    "from model import JointCausalModel\n",
    "from utility import compute_class_weights, label_value_counts\n",
    "from dataset_collator import CausalDataset, CausalDatasetCollator\n",
    "from config import id2label_cls, id2label_bio, id2label_rel\n",
    "from evaluate_joint_causal_model import evaluate_model, print_eval_report\n",
    "from trainer import train_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"C:\\\\Users\\\\norouzin\\\\Desktop\\\\JointLearning\\\\datasets\\\\expert_multi_task_data\\\\train.csv\"\n",
    "val_data_path = \"C:\\\\Users\\\\norouzin\\\\Desktop\\\\JointLearning\\\\datasets\\\\expert_multi_task_data\\\\val.csv\"\n",
    "test_data_path = \"C:\\\\Users\\\\norouzin\\\\Desktop\\\\JointLearning\\\\datasets\\\\expert_multi_task_data\\\\test.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caee3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CausalDataset(\n",
    "    train_df,\n",
    "    tokenizer_name='bert-base-uncased',\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "val_dataset = CausalDataset(\n",
    "    val_df,\n",
    "    tokenizer_name='bert-base-uncased',\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "test_dataset = CausalDataset(\n",
    "    test_df,\n",
    "    tokenizer_name='bert-base-uncased',\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd2fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_labels_value_counts:\n",
      " 0    1047\n",
      "1    1035\n",
      "Name: count, dtype: int64\n",
      "bio_labels_value_counts:\n",
      "  6      52764\n",
      " 3       8717\n",
      " 1       6948\n",
      "-100     4164\n",
      " 2       1320\n",
      " 0       1179\n",
      " 5        483\n",
      " 4         79\n",
      "Name: count, dtype: int64\n",
      "rel_labels_value_counts:\n",
      " 0    2887\n",
      "1    1494\n",
      "Name: count, dtype: int64\n",
      "CLS Weights: tensor([0.0015, 0.0016])\n",
      "BIO Weights: tensor([0.0014, 0.0010, 0.0014, 0.0010, 0.0132, 0.0026, 0.0010])\n",
      "REL Weights: tensor([0.0011, 0.0013])\n"
     ]
    }
   ],
   "source": [
    "labels_flat = label_value_counts(train_dataset)\n",
    "# %%\n",
    "cls_label_flat = labels_flat[\"cls_labels_flat\"]\n",
    "bio_label_flat = labels_flat[\"bio_labels_flat\"]\n",
    "rel_label_flat = labels_flat[\"rel_labels_flat\"]\n",
    "# %%\n",
    "# Calculate class weights\n",
    "cls_weights = compute_class_weights(labels_list=cls_label_flat, num_classes=MODEL_CONFIG[\"num_cls_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "bio_weights = compute_class_weights(labels_list=bio_label_flat, num_classes=MODEL_CONFIG[\"num_bio_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "rel_weights = compute_class_weights(labels_list=rel_label_flat, num_classes=MODEL_CONFIG[\"num_rel_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "print(f\"CLS Weights: {cls_weights}\")\n",
    "print(f\"BIO Weights: {bio_weights}\")\n",
    "print(f\"REL Weights: {rel_weights}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98d81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CausalDatasetCollator(\n",
    "    tokenizer=train_dataset.tokenizer\n",
    ")\n",
    "# %%\n",
    "# take a 100 samples from train_dataset\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, random.sample(range(len(train_dataset)), 20))\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, random.sample(range(len(val_dataset)), 20))\n",
    "# %%\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09250461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JointCausalModel(\n",
    "    encoder_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    num_cls_labels=MODEL_CONFIG[\"num_cls_labels\"],\n",
    "    num_bio_labels=MODEL_CONFIG[\"num_bio_labels\"],\n",
    "    num_rel_labels=MODEL_CONFIG[\"num_rel_labels\"],\n",
    "    dropout=MODEL_CONFIG[\"dropout\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n",
    ")\n",
    "# %%\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"C:\\Users\\norouzin\\Desktop\\JointLearning\\src\\jointlearning\\tesbert\\best_bert_softmax_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0df434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Training]:   0%|          | 0/2 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 1/2 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           10.7024\n",
      "  Average Validation Loss:         3.4667\n",
      "  Overall Validation Avg F1 (Macro): 0.2483\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.3333\n",
      "    Macro Precision: 0.2500\n",
      "    Macro Recall:    0.5000\n",
      "    Accuracy:        0.5000\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.0000 (P=0.0000, R=0.0000, Support=10.0)\n",
      "      causal      : F1=0.6667 (P=0.5000, R=1.0000, Support=10.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.1358\n",
      "    Macro Precision: 0.1162\n",
      "    Macro Recall:    0.1634\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.000 (P=0.000, R=0.000, S=12.0)\n",
      "      I-C       : F1=0.000 (P=0.000, R=0.000, S=67.0)\n",
      "      B-E       : F1=0.000 (P=0.000, R=0.000, S=11.0)\n",
      "      I-E       : F1=0.000 (P=0.000, R=0.000, S=88.0)\n",
      "      I-CE      : F1=0.000 (P=0.000, R=0.000, S=0.0)\n",
      "      O         : F1=0.815 (P=0.697, R=0.981, S=413.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.2757\n",
      "    Macro Precision: 0.4122\n",
      "    Macro Recall:    0.4808\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.071 (P=0.500, R=0.038, S=26.0)\n",
      "      Rel_CE      : F1=0.480 (P=0.324, R=0.923, S=13.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.2483\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 2/2 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           6.7320\n",
      "  Average Validation Loss:         3.0232\n",
      "  Overall Validation Avg F1 (Macro): 0.3506\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.4872\n",
      "    Macro Precision: 0.5980\n",
      "    Macro Recall:    0.5500\n",
      "    Accuracy:        0.5500\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.3077 (P=0.6667, R=0.2000, Support=10.0)\n",
      "      causal      : F1=0.6667 (P=0.5294, R=0.9000, Support=10.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.1645\n",
      "    Macro Precision: 0.1398\n",
      "    Macro Recall:    0.2000\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.000 (P=0.000, R=0.000, S=12.0)\n",
      "      I-C       : F1=0.000 (P=0.000, R=0.000, S=67.0)\n",
      "      B-E       : F1=0.000 (P=0.000, R=0.000, S=11.0)\n",
      "      I-E       : F1=0.000 (P=0.000, R=0.000, S=88.0)\n",
      "      O         : F1=0.823 (P=0.699, R=1.000, S=413.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.4000\n",
      "    Macro Precision: 0.3333\n",
      "    Macro Recall:    0.5000\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.800 (P=0.667, R=1.000, S=26.0)\n",
      "      Rel_CE      : F1=0.000 (P=0.000, R=0.000, S=13.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.3506\n",
      "================================================================================\n",
      "\n",
      "Loading best model state (in memory) with F1: 0.3506\n",
      "Training history saved to src/jointlearning/tesbert\\training_history.json\n"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=2,\n",
    "        device=DEVICE,\n",
    "        id2label_cls=id2label_cls,\n",
    "        id2label_bio=id2label_bio,\n",
    "        id2label_rel=id2label_rel,\n",
    "        model_save_path=model_save_path,\n",
    "        scheduler=scheduler,\n",
    "        cls_class_weights=cls_weights,\n",
    "        bio_class_weights=bio_weights, # Only for softmax\n",
    "        rel_class_weights=rel_weights,\n",
    "        patience_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        seed=SEED,\n",
    "        max_grad_norm=TRAINING_CONFIG[\"gradient_clip_val\"],\n",
    "        eval_fn_metrics=evaluate_model, # Pass your evaluate_model function here\n",
    "        print_report_fn=print_eval_report # Pass your print_eval_report function here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79999d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function trainer.train_model(model: torch.nn.modules.module.Module, train_dataloader: torch.utils.data.dataloader.DataLoader, val_dataloader: torch.utils.data.dataloader.DataLoader, optimizer: torch.optim.optimizer.Optimizer, num_epochs: int, device: torch.device, id2label_cls: dict, id2label_bio: dict, id2label_rel: dict, model_save_path: str = 'best_model.pt', scheduler: torch.optim.lr_scheduler._LRScheduler = None, cls_class_weights: torch.Tensor = None, bio_class_weights: torch.Tensor = None, rel_class_weights: torch.Tensor = None, patience_epochs: int = 5, seed: int = 8642, max_grad_norm: float | None = 1.0, eval_fn_metrics=None, print_report_fn=None) -> tuple[torch.nn.modules.module.Module, dict]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.save_pretrained_model(\n",
    "    model=trained_model,\n",
    "    save_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65306f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8aeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
