{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnorouzini/JointLearning/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from config import DEVICE, SEED, MODEL_CONFIG, TRAINING_CONFIG, DATASET_CONFIG\n",
    "from model import JointCausalModel\n",
    "from utility import compute_class_weights, label_value_counts\n",
    "from dataset_collator import CausalDataset, CausalDatasetCollator\n",
    "from config import id2label_cls, id2label_bio, id2label_rel\n",
    "from evaluate_joint_causal_model import evaluate_model, print_eval_report\n",
    "from trainer import train_model\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from utility import freeze_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/train.csv\"\n",
    "val_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/val.csv\"\n",
    "test_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/test.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caee3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CausalDataset(\n",
    "    train_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "val_dataset = CausalDataset(\n",
    "    val_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "test_dataset = CausalDataset(\n",
    "    test_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd2fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_labels_value_counts:\n",
      " 0    1047\n",
      "1    1035\n",
      "Name: count, dtype: int64\n",
      "bio_labels_value_counts:\n",
      "  6      52764\n",
      " 3       8717\n",
      " 1       6948\n",
      "-100     4164\n",
      " 2       1320\n",
      " 0       1179\n",
      " 5        483\n",
      " 4         79\n",
      "Name: count, dtype: int64\n",
      "rel_labels_value_counts:\n",
      " 0    2887\n",
      "1    1494\n",
      "Name: count, dtype: int64\n",
      "CLS Weights: tensor([0.0015, 0.0016])\n",
      "BIO Weights: tensor([0.0014, 0.0010, 0.0014, 0.0010, 0.0132, 0.0026, 0.0010])\n",
      "REL Weights: tensor([0.0011, 0.0013])\n"
     ]
    }
   ],
   "source": [
    "labels_flat = label_value_counts(train_dataset)\n",
    "# %%\n",
    "cls_label_flat = labels_flat[\"cls_labels_flat\"]\n",
    "bio_label_flat = labels_flat[\"bio_labels_flat\"]\n",
    "rel_label_flat = labels_flat[\"rel_labels_flat\"]\n",
    "# %%\n",
    "# Calculate class weights\n",
    "cls_weights = compute_class_weights(labels_list=cls_label_flat, num_classes=MODEL_CONFIG[\"num_cls_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "bio_weights = compute_class_weights(labels_list=bio_label_flat, num_classes=MODEL_CONFIG[\"num_bio_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "rel_weights = compute_class_weights(labels_list=rel_label_flat, num_classes=MODEL_CONFIG[\"num_rel_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "print(f\"CLS Weights: {cls_weights}\")\n",
    "print(f\"BIO Weights: {bio_weights}\")\n",
    "print(f\"REL Weights: {rel_weights}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98d81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CausalDatasetCollator(\n",
    "    tokenizer=train_dataset.tokenizer\n",
    ")\n",
    "# %%\n",
    "# take a 100 samples from train_dataset\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, random.sample(range(len(train_dataset)), 20))\n",
    "# val_dataset = torch.utils.data.Subset(val_dataset, random.sample(range(len(val_dataset)), 20))\n",
    "# # %%\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6554c1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JointCausalModel(\n",
       "  (enc): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (cls_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       "  (bio_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=7, bias=True)\n",
       "  )\n",
       "  (rel_head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG[\"encoder_name\"])\n",
    "model_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt\"\n",
    "model = JointCausalModel(**MODEL_CONFIG)\n",
    "model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0701ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder layers are frozen successfully.\n"
     ]
    }
   ],
   "source": [
    "freeze_encoder_layers(model)\n",
    "# verify that the encoder layers are frozen\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder\" in name:\n",
    "        assert not param.requires_grad, f\"Parameter {name} is not frozen!\"\n",
    "print(\"Encoder layers are frozen successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n",
    ")\n",
    "# %%\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eaed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/expert_bert_GCE_Softmax_Freeze_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0df434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Configuration ---\n",
      "Device: cuda\n",
      "Number of Epochs: 30\n",
      "Seed: 8642\n",
      "Optimizer: AdamW (LR: 5e-05, Weight Decay: 0.01)\n",
      "Scheduler: ReduceLROnPlateau\n",
      "Max Grad Norm: 1.0 (Mode: L2 norm if enabled)\n",
      "Early Stopping Patience: 30\n",
      "Model Save Path: /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/expert_bert_GCE_Softmax_Freeze_model.pt\n",
      "Mode: Standard Training (CrossEntropy)\n",
      "Task loss weights not provided, using default: {'cls': 1.0, 'bio': 1.0, 'rel': 1.0}\n",
      "CLS Class Weights: Provided\n",
      "BIO Class Weights: Provided\n",
      "REL Class Weights: Provided\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Training]:   0%|          | 0/131 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 1/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           2.6753\n",
      "  Average Validation Loss:         1.3516\n",
      "  Overall Validation Avg F1 (Macro): 0.6891\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7533\n",
      "    Macro Precision: 0.7990\n",
      "    Macro Recall:    0.7632\n",
      "    Accuracy:        0.7600\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7128 (P=0.9116, R=0.5852, Support=229.0)\n",
      "      causal      : F1=0.7939 (P=0.6865, R=0.9412, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.3774\n",
      "    Macro Precision: 0.3883\n",
      "    Macro Recall:    0.3744\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.422 (P=0.429, R=0.414, S=263.0)\n",
      "      I-C       : F1=0.491 (P=0.489, R=0.494, S=1451.0)\n",
      "      B-E       : F1=0.283 (P=0.392, R=0.221, S=271.0)\n",
      "      I-E       : F1=0.579 (P=0.537, R=0.627, S=1846.0)\n",
      "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
      "      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)\n",
      "      O         : F1=0.867 (P=0.871, R=0.863, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9366\n",
      "    Macro Precision: 0.9294\n",
      "    Macro Recall:    0.9459\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.955 (P=0.977, R=0.934, S=604.0)\n",
      "      Rel_CE      : F1=0.918 (P=0.881, R=0.958, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6891\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 2/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4584\n",
      "  Average Validation Loss:         1.2655\n",
      "  Overall Validation Avg F1 (Macro): 0.7163\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7628\n",
      "    Macro Precision: 0.8069\n",
      "    Macro Recall:    0.7720\n",
      "    Accuracy:        0.7689\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7249 (P=0.9195, R=0.5983, Support=229.0)\n",
      "      causal      : F1=0.8008 (P=0.6944, R=0.9457, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4537\n",
      "    Macro Precision: 0.4426\n",
      "    Macro Recall:    0.4727\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.448 (P=0.426, R=0.471, S=263.0)\n",
      "      I-C       : F1=0.529 (P=0.541, R=0.518, S=1451.0)\n",
      "      B-E       : F1=0.360 (P=0.389, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.599 (P=0.565, R=0.638, S=1846.0)\n",
      "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
      "      I-CE      : F1=0.366 (P=0.296, R=0.481, S=77.0)\n",
      "      O         : F1=0.873 (P=0.881, R=0.865, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9322\n",
      "    Macro Precision: 0.9237\n",
      "    Macro Recall:    0.9442\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.951 (P=0.981, R=0.924, S=605.0)\n",
      "      Rel_CE      : F1=0.913 (P=0.867, R=0.965, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7163\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 3/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.3732\n",
      "  Average Validation Loss:         1.2208\n",
      "  Overall Validation Avg F1 (Macro): 0.7366\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7671\n",
      "    Macro Precision: 0.7969\n",
      "    Macro Recall:    0.7737\n",
      "    Accuracy:        0.7711\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7366 (P=0.8889, R=0.6288, Support=229.0)\n",
      "      causal      : F1=0.7976 (P=0.7049, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5014\n",
      "    Macro Precision: 0.5030\n",
      "    Macro Recall:    0.5055\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.448 (P=0.478, R=0.422, S=263.0)\n",
      "      I-C       : F1=0.538 (P=0.540, R=0.536, S=1451.0)\n",
      "      B-E       : F1=0.357 (P=0.422, R=0.310, S=271.0)\n",
      "      I-E       : F1=0.602 (P=0.569, R=0.639, S=1846.0)\n",
      "      B-CE      : F1=0.258 (P=0.250, R=0.267, S=15.0)\n",
      "      I-CE      : F1=0.429 (P=0.380, R=0.494, S=77.0)\n",
      "      O         : F1=0.876 (P=0.881, R=0.871, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9412\n",
      "    Macro Precision: 0.9352\n",
      "    Macro Recall:    0.9486\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.959 (P=0.976, R=0.942, S=607.0)\n",
      "      Rel_CE      : F1=0.924 (P=0.894, R=0.955, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7366\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 4/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.3447\n",
      "  Average Validation Loss:         1.1994\n",
      "  Overall Validation Avg F1 (Macro): 0.7426\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7793\n",
      "    Macro Precision: 0.8032\n",
      "    Macro Recall:    0.7845\n",
      "    Accuracy:        0.7822\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7538 (P=0.8876, R=0.6550, Support=229.0)\n",
      "      causal      : F1=0.8048 (P=0.7189, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5026\n",
      "    Macro Precision: 0.4812\n",
      "    Macro Recall:    0.5515\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.459 (P=0.429, R=0.494, S=263.0)\n",
      "      I-C       : F1=0.551 (P=0.522, R=0.584, S=1451.0)\n",
      "      B-E       : F1=0.357 (P=0.386, R=0.332, S=271.0)\n",
      "      I-E       : F1=0.607 (P=0.558, R=0.665, S=1846.0)\n",
      "      B-CE      : F1=0.222 (P=0.146, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.450 (P=0.434, R=0.468, S=77.0)\n",
      "      O         : F1=0.872 (P=0.895, R=0.850, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9459\n",
      "    Macro Precision: 0.9398\n",
      "    Macro Recall:    0.9532\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.962 (P=0.979, R=0.945, S=602.0)\n",
      "      Rel_CE      : F1=0.930 (P=0.900, R=0.961, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7426\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 5/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.3013\n",
      "  Average Validation Loss:         1.1901\n",
      "  Overall Validation Avg F1 (Macro): 0.7393\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7793\n",
      "    Macro Precision: 0.8032\n",
      "    Macro Recall:    0.7845\n",
      "    Accuracy:        0.7822\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7538 (P=0.8876, R=0.6550, Support=229.0)\n",
      "      causal      : F1=0.8048 (P=0.7189, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5061\n",
      "    Macro Precision: 0.4897\n",
      "    Macro Recall:    0.5480\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.456 (P=0.434, R=0.479, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.543, R=0.553, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.395, R=0.332, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.578, R=0.645, S=1846.0)\n",
      "      B-CE      : F1=0.226 (P=0.149, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.466 (P=0.442, R=0.494, S=77.0)\n",
      "      O         : F1=0.876 (P=0.887, R=0.866, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9324\n",
      "    Macro Precision: 0.9235\n",
      "    Macro Recall:    0.9452\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.952 (P=0.982, R=0.923, S=607.0)\n",
      "      Rel_CE      : F1=0.913 (P=0.865, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7426. Patience: 1/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 6/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2789\n",
      "  Average Validation Loss:         1.1951\n",
      "  Overall Validation Avg F1 (Macro): 0.7430\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7793\n",
      "    Macro Precision: 0.8032\n",
      "    Macro Recall:    0.7845\n",
      "    Accuracy:        0.7822\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7538 (P=0.8876, R=0.6550, Support=229.0)\n",
      "      causal      : F1=0.8048 (P=0.7189, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5073\n",
      "    Macro Precision: 0.4905\n",
      "    Macro Recall:    0.5483\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.455 (P=0.442, R=0.468, S=263.0)\n",
      "      I-C       : F1=0.550 (P=0.550, R=0.549, S=1451.0)\n",
      "      B-E       : F1=0.356 (P=0.385, R=0.332, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.576, R=0.649, S=1846.0)\n",
      "      B-CE      : F1=0.233 (P=0.156, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.470 (P=0.438, R=0.506, S=77.0)\n",
      "      O         : F1=0.877 (P=0.887, R=0.867, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9426\n",
      "    Macro Precision: 0.9351\n",
      "    Macro Recall:    0.9523\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.959 (P=0.983, R=0.937, S=602.0)\n",
      "      Rel_CE      : F1=0.926 (P=0.888, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7430\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 7/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2771\n",
      "  Average Validation Loss:         1.1754\n",
      "  Overall Validation Avg F1 (Macro): 0.7418\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7840\n",
      "    Macro Precision: 0.8065\n",
      "    Macro Recall:    0.7889\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7600 (P=0.8889, R=0.6638, Support=229.0)\n",
      "      causal      : F1=0.8080 (P=0.7240, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4860\n",
      "    Macro Recall:    0.5382\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.453 (P=0.442, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.549 (P=0.553, R=0.545, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.576, R=0.647, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9392\n",
      "    Macro Precision: 0.9312\n",
      "    Macro Recall:    0.9500\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.957 (P=0.983, R=0.932, S=605.0)\n",
      "      Rel_CE      : F1=0.922 (P=0.880, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7430. Patience: 1/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 8/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2775\n",
      "  Average Validation Loss:         1.1733\n",
      "  Overall Validation Avg F1 (Macro): 0.7402\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5022\n",
      "    Macro Precision: 0.4862\n",
      "    Macro Recall:    0.5382\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.444, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.549 (P=0.553, R=0.545, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.576, R=0.647, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9367\n",
      "    Macro Precision: 0.9285\n",
      "    Macro Recall:    0.9480\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.955 (P=0.982, R=0.928, S=600.0)\n",
      "      Rel_CE      : F1=0.919 (P=0.875, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7430. Patience: 2/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 9/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.3126\n",
      "  Average Validation Loss:         1.1644\n",
      "  Overall Validation Avg F1 (Macro): 0.7464\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7840\n",
      "    Macro Precision: 0.8065\n",
      "    Macro Recall:    0.7889\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7600 (P=0.8889, R=0.6638, Support=229.0)\n",
      "      causal      : F1=0.8080 (P=0.7240, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5020\n",
      "    Macro Precision: 0.4862\n",
      "    Macro Recall:    0.5380\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.444, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.549 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9531\n",
      "    Macro Precision: 0.9474\n",
      "    Macro Recall:    0.9599\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.967 (P=0.983, R=0.952, S=605.0)\n",
      "      Rel_CE      : F1=0.939 (P=0.912, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7464\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 10/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2580\n",
      "  Average Validation Loss:         1.1784\n",
      "  Overall Validation Avg F1 (Macro): 0.7455\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5020\n",
      "    Macro Precision: 0.4862\n",
      "    Macro Recall:    0.5380\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.444, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.577, R=0.647, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9530\n",
      "    Macro Precision: 0.9473\n",
      "    Macro Recall:    0.9597\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.967 (P=0.983, R=0.952, S=600.0)\n",
      "      Rel_CE      : F1=0.939 (P=0.912, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 1/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 11/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2633\n",
      "  Average Validation Loss:         1.1855\n",
      "  Overall Validation Avg F1 (Macro): 0.7440\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5020\n",
      "    Macro Precision: 0.4862\n",
      "    Macro Recall:    0.5380\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.444, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.577, R=0.647, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9485\n",
      "    Macro Precision: 0.9419\n",
      "    Macro Recall:    0.9566\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.964 (P=0.983, R=0.946, S=606.0)\n",
      "      Rel_CE      : F1=0.933 (P=0.901, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 2/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 12/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2808\n",
      "  Average Validation Loss:         1.1722\n",
      "  Overall Validation Avg F1 (Macro): 0.7449\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5022\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5380\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.610 (P=0.577, R=0.647, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9508\n",
      "    Macro Precision: 0.9446\n",
      "    Macro Recall:    0.9583\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.966 (P=0.983, R=0.949, S=606.0)\n",
      "      Rel_CE      : F1=0.936 (P=0.906, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 3/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 13/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2847\n",
      "  Average Validation Loss:         1.1658\n",
      "  Overall Validation Avg F1 (Macro): 0.7425\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9438\n",
      "    Macro Precision: 0.9365\n",
      "    Macro Recall:    0.9533\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.960 (P=0.983, R=0.939, S=605.0)\n",
      "      Rel_CE      : F1=0.927 (P=0.890, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 4/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 14/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2748\n",
      "  Average Validation Loss:         1.1835\n",
      "  Overall Validation Avg F1 (Macro): 0.7432\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9459\n",
      "    Macro Precision: 0.9390\n",
      "    Macro Recall:    0.9546\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.962 (P=0.983, R=0.941, S=597.0)\n",
      "      Rel_CE      : F1=0.930 (P=0.896, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 5/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 15/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2603\n",
      "  Average Validation Loss:         1.1511\n",
      "  Overall Validation Avg F1 (Macro): 0.7463\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9553\n",
      "    Macro Precision: 0.9501\n",
      "    Macro Recall:    0.9613\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.969 (P=0.983, R=0.955, S=599.0)\n",
      "      Rel_CE      : F1=0.942 (P=0.917, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 6/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 16/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2807\n",
      "  Average Validation Loss:         1.1576\n",
      "  Overall Validation Avg F1 (Macro): 0.7418\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9416\n",
      "    Macro Precision: 0.9338\n",
      "    Macro Recall:    0.9518\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.959 (P=0.983, R=0.936, S=608.0)\n",
      "      Rel_CE      : F1=0.924 (P=0.885, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 7/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 17/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2724\n",
      "  Average Validation Loss:         1.1958\n",
      "  Overall Validation Avg F1 (Macro): 0.7441\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9485\n",
      "    Macro Precision: 0.9419\n",
      "    Macro Recall:    0.9566\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.964 (P=0.983, R=0.946, S=606.0)\n",
      "      Rel_CE      : F1=0.933 (P=0.901, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 8/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 18/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2623\n",
      "  Average Validation Loss:         1.1739\n",
      "  Overall Validation Avg F1 (Macro): 0.7433\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9462\n",
      "    Macro Precision: 0.9392\n",
      "    Macro Recall:    0.9550\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.962 (P=0.983, R=0.942, S=607.0)\n",
      "      Rel_CE      : F1=0.930 (P=0.896, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 9/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 19/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2722\n",
      "  Average Validation Loss:         1.1644\n",
      "  Overall Validation Avg F1 (Macro): 0.7429\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9450\n",
      "    Macro Precision: 0.9378\n",
      "    Macro Recall:    0.9542\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.961 (P=0.983, R=0.941, S=607.0)\n",
      "      Rel_CE      : F1=0.929 (P=0.893, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 10/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 20/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2670\n",
      "  Average Validation Loss:         1.1681\n",
      "  Overall Validation Avg F1 (Macro): 0.7437\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9473\n",
      "    Macro Precision: 0.9405\n",
      "    Macro Recall:    0.9558\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.963 (P=0.983, R=0.944, S=605.0)\n",
      "      Rel_CE      : F1=0.932 (P=0.898, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 11/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 21/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2823\n",
      "  Average Validation Loss:         1.1783\n",
      "  Overall Validation Avg F1 (Macro): 0.7414\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9405\n",
      "    Macro Precision: 0.9326\n",
      "    Macro Recall:    0.9511\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.958 (P=0.983, R=0.934, S=610.0)\n",
      "      Rel_CE      : F1=0.923 (P=0.882, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 12/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 22/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2859\n",
      "  Average Validation Loss:         1.1872\n",
      "  Overall Validation Avg F1 (Macro): 0.7402\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9369\n",
      "    Macro Precision: 0.9286\n",
      "    Macro Recall:    0.9483\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.955 (P=0.983, R=0.929, S=605.0)\n",
      "      Rel_CE      : F1=0.919 (P=0.875, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 13/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 23/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2718\n",
      "  Average Validation Loss:         1.1748\n",
      "  Overall Validation Avg F1 (Macro): 0.7422\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9429\n",
      "    Macro Precision: 0.9352\n",
      "    Macro Recall:    0.9528\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.960 (P=0.983, R=0.938, S=612.0)\n",
      "      Rel_CE      : F1=0.926 (P=0.888, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 14/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 24/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2873\n",
      "  Average Validation Loss:         1.1782\n",
      "  Overall Validation Avg F1 (Macro): 0.7452\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9520\n",
      "    Macro Precision: 0.9460\n",
      "    Macro Recall:    0.9592\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.966 (P=0.983, R=0.951, S=607.0)\n",
      "      Rel_CE      : F1=0.938 (P=0.909, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 15/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 25/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2721\n",
      "  Average Validation Loss:         1.1564\n",
      "  Overall Validation Avg F1 (Macro): 0.7425\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9437\n",
      "    Macro Precision: 0.9364\n",
      "    Macro Recall:    0.9531\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.960 (P=0.983, R=0.938, S=601.0)\n",
      "      Rel_CE      : F1=0.927 (P=0.890, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 16/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 26/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2623\n",
      "  Average Validation Loss:         1.1701\n",
      "  Overall Validation Avg F1 (Macro): 0.7426\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9440\n",
      "    Macro Precision: 0.9365\n",
      "    Macro Recall:    0.9535\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.961 (P=0.983, R=0.939, S=610.0)\n",
      "      Rel_CE      : F1=0.927 (P=0.890, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 17/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 27/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2517\n",
      "  Average Validation Loss:         1.1758\n",
      "  Overall Validation Avg F1 (Macro): 0.7433\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9462\n",
      "    Macro Precision: 0.9392\n",
      "    Macro Recall:    0.9550\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.962 (P=0.983, R=0.942, S=606.0)\n",
      "      Rel_CE      : F1=0.930 (P=0.896, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 18/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 28/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2825\n",
      "  Average Validation Loss:         1.1708\n",
      "  Overall Validation Avg F1 (Macro): 0.7425\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9438\n",
      "    Macro Precision: 0.9365\n",
      "    Macro Recall:    0.9533\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.960 (P=0.983, R=0.939, S=605.0)\n",
      "      Rel_CE      : F1=0.927 (P=0.890, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 19/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 29/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2647\n",
      "  Average Validation Loss:         1.1442\n",
      "  Overall Validation Avg F1 (Macro): 0.7406\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9381\n",
      "    Macro Precision: 0.9299\n",
      "    Macro Recall:    0.9492\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.956 (P=0.983, R=0.931, S=606.0)\n",
      "      Rel_CE      : F1=0.920 (P=0.877, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 20/30\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 30/30 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2699\n",
      "  Average Validation Loss:         1.1746\n",
      "  Overall Validation Avg F1 (Macro): 0.7395\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7816\n",
      "    Macro Precision: 0.8048\n",
      "    Macro Recall:    0.7867\n",
      "    Accuracy:        0.7844\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7569 (P=0.8882, R=0.6594, Support=229.0)\n",
      "      causal      : F1=0.8064 (P=0.7214, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5021\n",
      "    Macro Precision: 0.4864\n",
      "    Macro Recall:    0.5379\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.454 (P=0.445, R=0.464, S=263.0)\n",
      "      I-C       : F1=0.548 (P=0.553, R=0.544, S=1451.0)\n",
      "      B-E       : F1=0.361 (P=0.391, R=0.336, S=271.0)\n",
      "      I-E       : F1=0.609 (P=0.576, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.211 (P=0.143, R=0.400, S=15.0)\n",
      "      I-CE      : F1=0.453 (P=0.411, R=0.506, S=77.0)\n",
      "      O         : F1=0.878 (P=0.886, R=0.869, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9349\n",
      "    Macro Precision: 0.9261\n",
      "    Macro Recall:    0.9471\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.954 (P=0.983, R=0.926, S=612.0)\n",
      "      Rel_CE      : F1=0.916 (P=0.870, R=0.968, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7464. Patience: 21/30\n",
      "================================================================================\n",
      "\n",
      "Loading best model state (in memory) with F1: 0.7464\n",
      "Training history saved to /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/training_history.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        device=DEVICE,\n",
    "        id2label_cls=id2label_cls,\n",
    "        id2label_bio=id2label_bio,\n",
    "        id2label_rel=id2label_rel,\n",
    "        model_save_path=model_save_path,\n",
    "        scheduler=scheduler,\n",
    "        cls_class_weights=cls_weights,\n",
    "        bio_class_weights=bio_weights, # Only for softmax\n",
    "        rel_class_weights=rel_weights,\n",
    "        patience_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        seed=SEED,\n",
    "        max_grad_norm=TRAINING_CONFIG[\"gradient_clip_val\"],\n",
    "        eval_fn_metrics=evaluate_model, # Pass your evaluate_model function here\n",
    "        print_report_fn=print_eval_report # Pass your print_eval_report function here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d65306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add8aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/tokenizer_config.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/special_tokens_map.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/vocab.txt',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/added_tokens.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tokenizer.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ef916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
