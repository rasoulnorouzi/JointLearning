{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnorouzini/JointLearning/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from config import DEVICE, SEED, MODEL_CONFIG, TRAINING_CONFIG, DATASET_CONFIG\n",
    "from model import JointCausalModel\n",
    "from utility import compute_class_weights, label_value_counts\n",
    "from dataset_collator import CausalDataset, CausalDatasetCollator\n",
    "from config import id2label_cls, id2label_bio, id2label_rel\n",
    "from evaluate_joint_causal_model import evaluate_model, print_eval_report\n",
    "from trainer import train_model\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from utility import freeze_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/train.csv\"\n",
    "val_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/val.csv\"\n",
    "test_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/test.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caee3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CausalDataset(\n",
    "    train_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "val_dataset = CausalDataset(\n",
    "    val_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "test_dataset = CausalDataset(\n",
    "    test_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd2fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_labels_value_counts:\n",
      " 0    1047\n",
      "1    1035\n",
      "Name: count, dtype: int64\n",
      "bio_labels_value_counts:\n",
      "  6      52764\n",
      " 3       8717\n",
      " 1       6948\n",
      "-100     4164\n",
      " 2       1320\n",
      " 0       1179\n",
      " 5        483\n",
      " 4         79\n",
      "Name: count, dtype: int64\n",
      "rel_labels_value_counts:\n",
      " 0    2887\n",
      "1    1494\n",
      "Name: count, dtype: int64\n",
      "CLS Weights: tensor([0.0015, 0.0016])\n",
      "BIO Weights: tensor([0.0014, 0.0010, 0.0014, 0.0010, 0.0132, 0.0026, 0.0010])\n",
      "REL Weights: tensor([0.0011, 0.0013])\n"
     ]
    }
   ],
   "source": [
    "labels_flat = label_value_counts(train_dataset)\n",
    "# %%\n",
    "cls_label_flat = labels_flat[\"cls_labels_flat\"]\n",
    "bio_label_flat = labels_flat[\"bio_labels_flat\"]\n",
    "rel_label_flat = labels_flat[\"rel_labels_flat\"]\n",
    "# %%\n",
    "# Calculate class weights\n",
    "cls_weights = compute_class_weights(labels_list=cls_label_flat, num_classes=MODEL_CONFIG[\"num_cls_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "bio_weights = compute_class_weights(labels_list=bio_label_flat, num_classes=MODEL_CONFIG[\"num_bio_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "rel_weights = compute_class_weights(labels_list=rel_label_flat, num_classes=MODEL_CONFIG[\"num_rel_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "print(f\"CLS Weights: {cls_weights}\")\n",
    "print(f\"BIO Weights: {bio_weights}\")\n",
    "print(f\"REL Weights: {rel_weights}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98d81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CausalDatasetCollator(\n",
    "    tokenizer=train_dataset.tokenizer\n",
    ")\n",
    "# %%\n",
    "# take a 100 samples from train_dataset\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, random.sample(range(len(train_dataset)), 20))\n",
    "# val_dataset = torch.utils.data.Subset(val_dataset, random.sample(range(len(val_dataset)), 20))\n",
    "# # %%\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6554c1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JointCausalModel(\n",
       "  (enc): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (cls_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       "  (bio_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=7, bias=True)\n",
       "  )\n",
       "  (rel_head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG[\"encoder_name\"])\n",
    "model_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt\"\n",
    "model = JointCausalModel(**MODEL_CONFIG)\n",
    "model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0701ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder layers are frozen successfully.\n"
     ]
    }
   ],
   "source": [
    "freeze_encoder_layers(model)\n",
    "# verify that the encoder layers are frozen\n",
    "for name, param in model.named_parameters():\n",
    "    if \"encoder\" in name:\n",
    "        assert not param.requires_grad, f\"Parameter {name} is not frozen!\"\n",
    "print(\"Encoder layers are frozen successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n",
    ")\n",
    "# %%\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eaed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/expert_bert_GCE_Softmax_Freeze_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0df434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Configuration ---\n",
      "Device: cuda\n",
      "Number of Epochs: 20\n",
      "Seed: 8642\n",
      "Optimizer: AdamW (LR: 1e-05, Weight Decay: 0.1)\n",
      "Scheduler: ReduceLROnPlateau\n",
      "Gradient Clipping: Enabled (Max Norm: 1.0)\n",
      "Early Stopping Patience: 20\n",
      "Model Save Path: /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/expert_bert_GCE_Softmax_Freeze_model.pt\n",
      "Mode: Standard Training (CrossEntropy)\n",
      "Task loss weights not provided, using default: {'cls': 1.0, 'bio': 1.0, 'rel': 1.0}\n",
      "CLS Class Weights: Provided\n",
      "BIO Class Weights: Provided\n",
      "REL Class Weights: Provided\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]:   0%|          | 0/131 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 1/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           3.8062\n",
      "  Average Validation Loss:         3.3185\n",
      "  Overall Validation Avg F1 (Macro): 0.7095\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7620\n",
      "    Macro Precision: 0.7955\n",
      "    Macro Recall:    0.7694\n",
      "    Accuracy:        0.7667\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7287 (P=0.8924, R=0.6157, Support=229.0)\n",
      "      causal      : F1=0.7953 (P=0.6986, R=0.9231, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4495\n",
      "    Macro Precision: 0.4075\n",
      "    Macro Recall:    0.5407\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.400 (P=0.345, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.560 (P=0.490, R=0.653, S=1451.0)\n",
      "      B-E       : F1=0.364 (P=0.326, R=0.413, S=271.0)\n",
      "      I-E       : F1=0.580 (P=0.520, R=0.654, S=1846.0)\n",
      "      B-CE      : F1=0.122 (P=0.088, R=0.200, S=15.0)\n",
      "      I-CE      : F1=0.266 (P=0.172, R=0.584, S=77.0)\n",
      "      O         : F1=0.855 (P=0.911, R=0.805, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9170\n",
      "    Macro Precision: 0.9118\n",
      "    Macro Recall:    0.9233\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.942 (P=0.957, R=0.927, S=604.0)\n",
      "      Rel_CE      : F1=0.892 (P=0.866, R=0.919, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7095\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 2/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           2.4599\n",
      "  Average Validation Loss:         1.8608\n",
      "  Overall Validation Avg F1 (Macro): 0.7030\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7607\n",
      "    Macro Precision: 0.7872\n",
      "    Macro Recall:    0.7669\n",
      "    Accuracy:        0.7644\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7310 (P=0.8727, R=0.6288, Support=229.0)\n",
      "      causal      : F1=0.7905 (P=0.7018, R=0.9050, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4506\n",
      "    Macro Precision: 0.4082\n",
      "    Macro Recall:    0.5467\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.409 (P=0.351, R=0.490, S=263.0)\n",
      "      I-C       : F1=0.556 (P=0.501, R=0.624, S=1451.0)\n",
      "      B-E       : F1=0.367 (P=0.317, R=0.435, S=271.0)\n",
      "      I-E       : F1=0.572 (P=0.529, R=0.622, S=1846.0)\n",
      "      B-CE      : F1=0.127 (P=0.083, R=0.267, S=15.0)\n",
      "      I-CE      : F1=0.266 (P=0.173, R=0.571, S=77.0)\n",
      "      O         : F1=0.857 (P=0.902, R=0.816, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8975\n",
      "    Macro Precision: 0.8902\n",
      "    Macro Recall:    0.9077\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.927 (P=0.953, R=0.902, S=605.0)\n",
      "      Rel_CE      : F1=0.868 (P=0.827, R=0.913, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7095. Patience: 1/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 3/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.7743\n",
      "  Average Validation Loss:         1.4442\n",
      "  Overall Validation Avg F1 (Macro): 0.7126\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7664\n",
      "    Macro Precision: 0.7849\n",
      "    Macro Recall:    0.7709\n",
      "    Accuracy:        0.7689\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7426 (P=0.8571, R=0.6550, Support=229.0)\n",
      "      causal      : F1=0.7903 (P=0.7127, R=0.8869, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4601\n",
      "    Macro Precision: 0.4204\n",
      "    Macro Recall:    0.5658\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.420 (P=0.370, R=0.487, S=263.0)\n",
      "      I-C       : F1=0.543 (P=0.520, R=0.567, S=1451.0)\n",
      "      B-E       : F1=0.389 (P=0.341, R=0.454, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.538, R=0.592, S=1846.0)\n",
      "      B-CE      : F1=0.177 (P=0.109, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.265 (P=0.174, R=0.558, S=77.0)\n",
      "      O         : F1=0.862 (P=0.891, R=0.836, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9113\n",
      "    Macro Precision: 0.9055\n",
      "    Macro Recall:    0.9185\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.938 (P=0.956, R=0.921, S=607.0)\n",
      "      Rel_CE      : F1=0.885 (P=0.855, R=0.916, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7126\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 4/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.5512\n",
      "  Average Validation Loss:         1.3700\n",
      "  Overall Validation Avg F1 (Macro): 0.7168\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7703\n",
      "    Macro Precision: 0.7937\n",
      "    Macro Recall:    0.7756\n",
      "    Accuracy:        0.7733\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7437 (P=0.8757, R=0.6463, Support=229.0)\n",
      "      causal      : F1=0.7968 (P=0.7117, R=0.9050, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4584\n",
      "    Macro Precision: 0.4230\n",
      "    Macro Recall:    0.5623\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.426 (P=0.383, R=0.479, S=263.0)\n",
      "      I-C       : F1=0.537 (P=0.526, R=0.549, S=1451.0)\n",
      "      B-E       : F1=0.355 (P=0.322, R=0.395, S=271.0)\n",
      "      I-E       : F1=0.560 (P=0.546, R=0.575, S=1846.0)\n",
      "      B-CE      : F1=0.190 (P=0.116, R=0.533, S=15.0)\n",
      "      I-CE      : F1=0.276 (P=0.183, R=0.558, S=77.0)\n",
      "      O         : F1=0.865 (P=0.885, R=0.846, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9216\n",
      "    Macro Precision: 0.9168\n",
      "    Macro Recall:    0.9272\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.959, R=0.932, S=602.0)\n",
      "      Rel_CE      : F1=0.898 (P=0.875, R=0.923, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7168\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 5/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4683\n",
      "  Average Validation Loss:         1.3232\n",
      "  Overall Validation Avg F1 (Macro): 0.7202\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7850\n",
      "    Macro Precision: 0.7999\n",
      "    Macro Recall:    0.7885\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7659 (P=0.8674, R=0.6856, Support=229.0)\n",
      "      causal      : F1=0.8041 (P=0.7323, R=0.8914, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4559\n",
      "    Macro Precision: 0.4288\n",
      "    Macro Recall:    0.5432\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.430 (P=0.398, R=0.468, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.512, S=1451.0)\n",
      "      B-E       : F1=0.347 (P=0.331, R=0.365, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.557, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.167 (P=0.101, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.880, R=0.861, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9197\n",
      "    Macro Precision: 0.9139\n",
      "    Macro Recall:    0.9267\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.944 (P=0.961, R=0.928, S=607.0)\n",
      "      Rel_CE      : F1=0.895 (P=0.867, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7202\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 6/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4650\n",
      "  Average Validation Loss:         1.3291\n",
      "  Overall Validation Avg F1 (Macro): 0.7206\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4552\n",
      "    Macro Precision: 0.4285\n",
      "    Macro Recall:    0.5419\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.429 (P=0.397, R=0.468, S=263.0)\n",
      "      I-C       : F1=0.523 (P=0.541, R=0.507, S=1451.0)\n",
      "      B-E       : F1=0.345 (P=0.330, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.570, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9217\n",
      "    Macro Precision: 0.9164\n",
      "    Macro Recall:    0.9280\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.961, R=0.930, S=602.0)\n",
      "      Rel_CE      : F1=0.898 (P=0.872, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7206\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 7/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4337\n",
      "  Average Validation Loss:         1.3105\n",
      "  Overall Validation Avg F1 (Macro): 0.7210\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4565\n",
      "    Macro Precision: 0.4298\n",
      "    Macro Recall:    0.5431\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.434 (P=0.401, R=0.471, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.543, R=0.510, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.565 (P=0.559, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.871 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9219\n",
      "    Macro Precision: 0.9165\n",
      "    Macro Recall:    0.9282\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.961, R=0.931, S=605.0)\n",
      "      Rel_CE      : F1=0.898 (P=0.872, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7210\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 8/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4322\n",
      "  Average Validation Loss:         1.3029\n",
      "  Overall Validation Avg F1 (Macro): 0.7184\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4298\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.542, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9136\n",
      "    Macro Precision: 0.9070\n",
      "    Macro Recall:    0.9221\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.939 (P=0.960, R=0.918, S=600.0)\n",
      "      Rel_CE      : F1=0.889 (P=0.854, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7210. Patience: 1/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 9/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4562\n",
      "  Average Validation Loss:         1.2954\n",
      "  Overall Validation Avg F1 (Macro): 0.7215\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4298\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.542, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9230\n",
      "    Macro Precision: 0.9179\n",
      "    Macro Recall:    0.9290\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.946 (P=0.961, R=0.932, S=605.0)\n",
      "      Rel_CE      : F1=0.900 (P=0.875, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7215\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 10/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4647\n",
      "  Average Validation Loss:         1.3114\n",
      "  Overall Validation Avg F1 (Macro): 0.7242\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4569\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5438\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.542, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.565 (P=0.558, R=0.572, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9309\n",
      "    Macro Precision: 0.9275\n",
      "    Macro Recall:    0.9346\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.952 (P=0.961, R=0.943, S=600.0)\n",
      "      Rel_CE      : F1=0.910 (P=0.894, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7242\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 11/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4309\n",
      "  Average Validation Loss:         1.2983\n",
      "  Overall Validation Avg F1 (Macro): 0.7216\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9230\n",
      "    Macro Precision: 0.9179\n",
      "    Macro Recall:    0.9291\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.946 (P=0.961, R=0.932, S=606.0)\n",
      "      Rel_CE      : F1=0.900 (P=0.875, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 1/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 12/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4421\n",
      "  Average Validation Loss:         1.2994\n",
      "  Overall Validation Avg F1 (Macro): 0.7231\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9276\n",
      "    Macro Precision: 0.9235\n",
      "    Macro Recall:    0.9324\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.950 (P=0.961, R=0.939, S=606.0)\n",
      "      Rel_CE      : F1=0.905 (P=0.886, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 2/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 13/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4368\n",
      "  Average Validation Loss:         1.2903\n",
      "  Overall Validation Avg F1 (Macro): 0.7208\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9207\n",
      "    Macro Precision: 0.9152\n",
      "    Macro Recall:    0.9274\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.961, R=0.929, S=605.0)\n",
      "      Rel_CE      : F1=0.897 (P=0.870, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 3/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 14/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4119\n",
      "  Average Validation Loss:         1.3080\n",
      "  Overall Validation Avg F1 (Macro): 0.7222\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9249\n",
      "    Macro Precision: 0.9204\n",
      "    Macro Recall:    0.9302\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.947 (P=0.960, R=0.935, S=597.0)\n",
      "      Rel_CE      : F1=0.903 (P=0.880, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 4/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 15/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4343\n",
      "  Average Validation Loss:         1.2775\n",
      "  Overall Validation Avg F1 (Macro): 0.7226\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4569\n",
      "    Macro Precision: 0.4300\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.871 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9262\n",
      "    Macro Precision: 0.9218\n",
      "    Macro Recall:    0.9312\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.948 (P=0.961, R=0.937, S=599.0)\n",
      "      Rel_CE      : F1=0.904 (P=0.883, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 5/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 16/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4659\n",
      "  Average Validation Loss:         1.2673\n",
      "  Overall Validation Avg F1 (Macro): 0.7186\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4569\n",
      "    Macro Precision: 0.4300\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.871 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9140\n",
      "    Macro Precision: 0.9073\n",
      "    Macro Recall:    0.9226\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.939 (P=0.960, R=0.919, S=608.0)\n",
      "      Rel_CE      : F1=0.889 (P=0.854, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 6/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 17/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4124\n",
      "  Average Validation Loss:         1.3197\n",
      "  Overall Validation Avg F1 (Macro): 0.7219\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4569\n",
      "    Macro Precision: 0.4300\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.871 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9242\n",
      "    Macro Precision: 0.9193\n",
      "    Macro Recall:    0.9299\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.947 (P=0.961, R=0.934, S=606.0)\n",
      "      Rel_CE      : F1=0.901 (P=0.878, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 7/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 18/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4174\n",
      "  Average Validation Loss:         1.2889\n",
      "  Overall Validation Avg F1 (Macro): 0.7227\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4569\n",
      "    Macro Precision: 0.4300\n",
      "    Macro Recall:    0.5437\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.527 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.871 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9265\n",
      "    Macro Precision: 0.9221\n",
      "    Macro Recall:    0.9316\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.949 (P=0.961, R=0.937, S=607.0)\n",
      "      Rel_CE      : F1=0.904 (P=0.883, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 8/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 19/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4301\n",
      "  Average Validation Loss:         1.2846\n",
      "  Overall Validation Avg F1 (Macro): 0.7231\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5436\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9277\n",
      "    Macro Precision: 0.9235\n",
      "    Macro Recall:    0.9324\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.950 (P=0.961, R=0.939, S=607.0)\n",
      "      Rel_CE      : F1=0.905 (P=0.886, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 9/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 20/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.4166\n",
      "  Average Validation Loss:         1.3057\n",
      "  Overall Validation Avg F1 (Macro): 0.7208\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7848\n",
      "    Macro Precision: 0.8011\n",
      "    Macro Recall:    0.7886\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7647 (P=0.8715, R=0.6812, Support=229.0)\n",
      "      causal      : F1=0.8049 (P=0.7306, R=0.8959, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4568\n",
      "    Macro Precision: 0.4299\n",
      "    Macro Recall:    0.5436\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.436 (P=0.403, R=0.475, S=263.0)\n",
      "      I-C       : F1=0.526 (P=0.543, R=0.511, S=1451.0)\n",
      "      B-E       : F1=0.346 (P=0.331, R=0.362, S=271.0)\n",
      "      I-E       : F1=0.564 (P=0.558, R=0.571, S=1846.0)\n",
      "      B-CE      : F1=0.169 (P=0.103, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.286 (P=0.192, R=0.558, S=77.0)\n",
      "      O         : F1=0.870 (P=0.879, R=0.862, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9207\n",
      "    Macro Precision: 0.9152\n",
      "    Macro Recall:    0.9274\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.961, R=0.929, S=605.0)\n",
      "      Rel_CE      : F1=0.897 (P=0.870, R=0.926, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7242. Patience: 10/20\n",
      "================================================================================\n",
      "\n",
      "Loading best model state (in memory) with F1: 0.7242\n",
      "Training history saved to /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/training_history.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        device=DEVICE,\n",
    "        id2label_cls=id2label_cls,\n",
    "        id2label_bio=id2label_bio,\n",
    "        id2label_rel=id2label_rel,\n",
    "        model_save_path=model_save_path,\n",
    "        scheduler=scheduler,\n",
    "        cls_class_weights=cls_weights,\n",
    "        bio_class_weights=bio_weights, # Only for softmax\n",
    "        rel_class_weights=rel_weights,\n",
    "        patience_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        seed=SEED,\n",
    "        max_grad_norm=TRAINING_CONFIG[\"gradient_clip_val\"],\n",
    "        eval_fn_metrics=evaluate_model, # Pass your evaluate_model function here\n",
    "        print_report_fn=print_eval_report # Pass your print_eval_report function here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d65306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add8aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/tokenizer_config.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/special_tokens_map.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/vocab.txt',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/added_tokens.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tokenizer.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_Softmax_Freeze/hf_expert_bert_GCE_Softmax_Freeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ef916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
