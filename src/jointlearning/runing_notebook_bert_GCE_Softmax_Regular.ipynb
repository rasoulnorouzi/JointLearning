{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnorouzini/JointLearning/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from config import DEVICE, SEED, MODEL_CONFIG, TRAINING_CONFIG, DATASET_CONFIG\n",
    "from model import JointCausalModel\n",
    "from utility import compute_class_weights, label_value_counts\n",
    "from dataset_collator import CausalDataset, CausalDatasetCollator\n",
    "from config import id2label_cls, id2label_bio, id2label_rel\n",
    "from evaluate_joint_causal_model import evaluate_model, print_eval_report\n",
    "from trainer import train_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/train.csv\"\n",
    "val_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/val.csv\"\n",
    "test_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/test.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caee3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CausalDataset(\n",
    "    train_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "val_dataset = CausalDataset(\n",
    "    val_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "test_dataset = CausalDataset(\n",
    "    test_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd2fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_labels_value_counts:\n",
      " 0    1047\n",
      "1    1035\n",
      "Name: count, dtype: int64\n",
      "bio_labels_value_counts:\n",
      "  6      52764\n",
      " 3       8717\n",
      " 1       6948\n",
      "-100     4164\n",
      " 2       1320\n",
      " 0       1179\n",
      " 5        483\n",
      " 4         79\n",
      "Name: count, dtype: int64\n",
      "rel_labels_value_counts:\n",
      " 0    2887\n",
      "1    1494\n",
      "Name: count, dtype: int64\n",
      "CLS Weights: tensor([0.0015, 0.0016])\n",
      "BIO Weights: tensor([0.0014, 0.0010, 0.0014, 0.0010, 0.0132, 0.0026, 0.0010])\n",
      "REL Weights: tensor([0.0011, 0.0013])\n"
     ]
    }
   ],
   "source": [
    "labels_flat = label_value_counts(train_dataset)\n",
    "# %%\n",
    "cls_label_flat = labels_flat[\"cls_labels_flat\"]\n",
    "bio_label_flat = labels_flat[\"bio_labels_flat\"]\n",
    "rel_label_flat = labels_flat[\"rel_labels_flat\"]\n",
    "# %%\n",
    "# Calculate class weights\n",
    "cls_weights = compute_class_weights(labels_list=cls_label_flat, num_classes=MODEL_CONFIG[\"num_cls_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "bio_weights = compute_class_weights(labels_list=bio_label_flat, num_classes=MODEL_CONFIG[\"num_bio_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "rel_weights = compute_class_weights(labels_list=rel_label_flat, num_classes=MODEL_CONFIG[\"num_rel_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "print(f\"CLS Weights: {cls_weights}\")\n",
    "print(f\"BIO Weights: {bio_weights}\")\n",
    "print(f\"REL Weights: {rel_weights}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98d81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CausalDatasetCollator(\n",
    "    tokenizer=train_dataset.tokenizer\n",
    ")\n",
    "# %%\n",
    "# take a 100 samples from train_dataset\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, random.sample(range(len(train_dataset)), 20))\n",
    "# val_dataset = torch.utils.data.Subset(val_dataset, random.sample(range(len(val_dataset)), 20))\n",
    "# # %%\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09250461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JointCausalModel(\n",
    "    encoder_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    num_cls_labels=MODEL_CONFIG[\"num_cls_labels\"],\n",
    "    num_bio_labels=MODEL_CONFIG[\"num_bio_labels\"],\n",
    "    num_rel_labels=MODEL_CONFIG[\"num_rel_labels\"],\n",
    "    dropout=MODEL_CONFIG[\"dropout\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n",
    ")\n",
    "# %%\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eaed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/expert_bert_softmax_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0df434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Training]:   0%|          | 0/131 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 1/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           4.6890\n",
      "  Average Validation Loss:         1.5285\n",
      "  Overall Validation Avg F1 (Macro): 0.6625\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7698\n",
      "    Macro Precision: 0.8133\n",
      "    Macro Recall:    0.7786\n",
      "    Accuracy:        0.7756\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7335 (P=0.9267, R=0.6070, Support=229.0)\n",
      "      causal      : F1=0.8061 (P=0.7000, R=0.9502, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.3752\n",
      "    Macro Precision: 0.4539\n",
      "    Macro Recall:    0.4179\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.323 (P=0.290, R=0.365, S=263.0)\n",
      "      I-C       : F1=0.453 (P=0.622, R=0.356, S=1451.0)\n",
      "      B-E       : F1=0.049 (P=0.583, R=0.026, S=271.0)\n",
      "      I-E       : F1=0.563 (P=0.459, R=0.729, S=1846.0)\n",
      "      B-CE      : F1=0.215 (P=0.140, R=0.467, S=15.0)\n",
      "      I-CE      : F1=0.146 (P=0.196, R=0.117, S=77.0)\n",
      "      O         : F1=0.876 (P=0.887, R=0.866, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8424\n",
      "    Macro Precision: 0.8382\n",
      "    Macro Recall:    0.8476\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.890 (P=0.904, R=0.876, S=604.0)\n",
      "      Rel_CE      : F1=0.795 (P=0.772, R=0.819, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6625\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 2/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           2.9168\n",
      "  Average Validation Loss:         1.2967\n",
      "  Overall Validation Avg F1 (Macro): 0.7052\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7828\n",
      "    Macro Precision: 0.8147\n",
      "    Macro Recall:    0.7893\n",
      "    Accuracy:        0.7867\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7538 (P=0.9130, R=0.6419, Support=229.0)\n",
      "      causal      : F1=0.8118 (P=0.7163, R=0.9367, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4805\n",
      "    Macro Precision: 0.5111\n",
      "    Macro Recall:    0.5302\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.467 (P=0.455, R=0.479, S=263.0)\n",
      "      I-C       : F1=0.600 (P=0.607, R=0.593, S=1451.0)\n",
      "      B-E       : F1=0.190 (P=0.554, R=0.114, S=271.0)\n",
      "      I-E       : F1=0.603 (P=0.565, R=0.646, S=1846.0)\n",
      "      B-CE      : F1=0.294 (P=0.189, R=0.667, S=15.0)\n",
      "      I-CE      : F1=0.321 (P=0.316, R=0.325, S=77.0)\n",
      "      O         : F1=0.890 (P=0.893, R=0.887, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8522\n",
      "    Macro Precision: 0.8445\n",
      "    Macro Recall:    0.8644\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.893 (P=0.927, R=0.861, S=605.0)\n",
      "      Rel_CE      : F1=0.811 (P=0.762, R=0.868, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7052\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 3/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.8206\n",
      "  Average Validation Loss:         1.4290\n",
      "  Overall Validation Avg F1 (Macro): 0.7387\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8198\n",
      "    Macro Precision: 0.8225\n",
      "    Macro Recall:    0.8208\n",
      "    Accuracy:        0.8200\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8146 (P=0.8558, R=0.7773, Support=229.0)\n",
      "      causal      : F1=0.8251 (P=0.7893, R=0.8643, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5391\n",
      "    Macro Precision: 0.4972\n",
      "    Macro Recall:    0.6335\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.516 (P=0.466, R=0.578, S=263.0)\n",
      "      I-C       : F1=0.621 (P=0.575, R=0.675, S=1451.0)\n",
      "      B-E       : F1=0.422 (P=0.391, R=0.458, S=271.0)\n",
      "      I-E       : F1=0.600 (P=0.639, R=0.566, S=1846.0)\n",
      "      B-CE      : F1=0.339 (P=0.227, R=0.667, S=15.0)\n",
      "      I-CE      : F1=0.384 (P=0.280, R=0.610, S=77.0)\n",
      "      O         : F1=0.891 (P=0.902, R=0.881, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8571\n",
      "    Macro Precision: 0.8493\n",
      "    Macro Recall:    0.8696\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.897 (P=0.931, R=0.865, S=607.0)\n",
      "      Rel_CE      : F1=0.817 (P=0.768, R=0.874, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7387\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 4/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           1.2496\n",
      "  Average Validation Loss:         1.6650\n",
      "  Overall Validation Avg F1 (Macro): 0.7494\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8332\n",
      "    Macro Precision: 0.8354\n",
      "    Macro Recall:    0.8340\n",
      "    Accuracy:        0.8333\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8292 (P=0.8667, R=0.7948, Support=229.0)\n",
      "      causal      : F1=0.8373 (P=0.8042, R=0.8733, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5523\n",
      "    Macro Precision: 0.5043\n",
      "    Macro Recall:    0.6333\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.474 (P=0.393, R=0.597, S=263.0)\n",
      "      I-C       : F1=0.638 (P=0.612, R=0.666, S=1451.0)\n",
      "      B-E       : F1=0.441 (P=0.393, R=0.502, S=271.0)\n",
      "      I-E       : F1=0.641 (P=0.623, R=0.661, S=1846.0)\n",
      "      B-CE      : F1=0.400 (P=0.300, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.376 (P=0.291, R=0.532, S=77.0)\n",
      "      O         : F1=0.895 (P=0.917, R=0.875, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8626\n",
      "    Macro Precision: 0.8583\n",
      "    Macro Recall:    0.8678\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.904 (P=0.918, R=0.890, S=602.0)\n",
      "      Rel_CE      : F1=0.821 (P=0.799, R=0.845, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7494\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 5/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.7662\n",
      "  Average Validation Loss:         1.8860\n",
      "  Overall Validation Avg F1 (Macro): 0.7494\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8372\n",
      "    Macro Precision: 0.8456\n",
      "    Macro Recall:    0.8391\n",
      "    Accuracy:        0.8378\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8274 (P=0.9021, R=0.7642, Support=229.0)\n",
      "      causal      : F1=0.8470 (P=0.7891, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5560\n",
      "    Macro Precision: 0.5033\n",
      "    Macro Recall:    0.6698\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.514 (P=0.449, R=0.601, S=263.0)\n",
      "      I-C       : F1=0.645 (P=0.625, R=0.667, S=1451.0)\n",
      "      B-E       : F1=0.451 (P=0.400, R=0.517, S=271.0)\n",
      "      I-E       : F1=0.639 (P=0.616, R=0.664, S=1846.0)\n",
      "      B-CE      : F1=0.305 (P=0.205, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.442 (P=0.311, R=0.766, S=77.0)\n",
      "      O         : F1=0.895 (P=0.918, R=0.874, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8551\n",
      "    Macro Precision: 0.8521\n",
      "    Macro Recall:    0.8585\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.900 (P=0.909, R=0.891, S=607.0)\n",
      "      Rel_CE      : F1=0.810 (P=0.795, R=0.826, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7494\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 6/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.6169\n",
      "  Average Validation Loss:         2.0160\n",
      "  Overall Validation Avg F1 (Macro): 0.7496\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8371\n",
      "    Macro Precision: 0.8465\n",
      "    Macro Recall:    0.8392\n",
      "    Accuracy:        0.8378\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8266 (P=0.9062, R=0.7598, Support=229.0)\n",
      "      causal      : F1=0.8476 (P=0.7868, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5635\n",
      "    Macro Precision: 0.5207\n",
      "    Macro Recall:    0.6464\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.506 (P=0.452, R=0.574, S=263.0)\n",
      "      I-C       : F1=0.639 (P=0.657, R=0.622, S=1451.0)\n",
      "      B-E       : F1=0.462 (P=0.416, R=0.520, S=271.0)\n",
      "      I-E       : F1=0.633 (P=0.622, R=0.643, S=1846.0)\n",
      "      B-CE      : F1=0.367 (P=0.265, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.439 (P=0.325, R=0.675, S=77.0)\n",
      "      O         : F1=0.899 (P=0.908, R=0.890, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8481\n",
      "    Macro Precision: 0.8521\n",
      "    Macro Recall:    0.8446\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.899 (P=0.889, R=0.909, S=602.0)\n",
      "      Rel_CE      : F1=0.797 (P=0.815, R=0.781, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7496\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 7/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.5364\n",
      "  Average Validation Loss:         2.1468\n",
      "  Overall Validation Avg F1 (Macro): 0.7532\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8345\n",
      "    Macro Precision: 0.8481\n",
      "    Macro Recall:    0.8372\n",
      "    Accuracy:        0.8356\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8213 (P=0.9189, R=0.7424, Support=229.0)\n",
      "      causal      : F1=0.8477 (P=0.7774, R=0.9321, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5712\n",
      "    Macro Precision: 0.5241\n",
      "    Macro Recall:    0.6583\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.518 (P=0.463, R=0.589, S=263.0)\n",
      "      I-C       : F1=0.649 (P=0.648, R=0.651, S=1451.0)\n",
      "      B-E       : F1=0.465 (P=0.429, R=0.509, S=271.0)\n",
      "      I-E       : F1=0.640 (P=0.607, R=0.677, S=1846.0)\n",
      "      B-CE      : F1=0.383 (P=0.281, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.444 (P=0.325, R=0.701, S=77.0)\n",
      "      O         : F1=0.898 (P=0.916, R=0.880, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8538\n",
      "    Macro Precision: 0.8565\n",
      "    Macro Recall:    0.8513\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.902 (P=0.896, R=0.909, S=605.0)\n",
      "      Rel_CE      : F1=0.805 (P=0.817, R=0.794, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7532\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 8/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4411\n",
      "  Average Validation Loss:         2.1058\n",
      "  Overall Validation Avg F1 (Macro): 0.7585\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8393\n",
      "    Macro Precision: 0.8493\n",
      "    Macro Recall:    0.8415\n",
      "    Accuracy:        0.8400\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8286 (P=0.9110, R=0.7598, Support=229.0)\n",
      "      causal      : F1=0.8500 (P=0.7876, R=0.9231, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5770\n",
      "    Macro Precision: 0.5374\n",
      "    Macro Recall:    0.6501\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.506 (P=0.455, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.648 (P=0.665, R=0.631, S=1451.0)\n",
      "      B-E       : F1=0.467 (P=0.431, R=0.509, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.640, R=0.629, S=1846.0)\n",
      "      B-CE      : F1=0.409 (P=0.310, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.474 (P=0.355, R=0.714, S=77.0)\n",
      "      O         : F1=0.901 (P=0.905, R=0.897, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8592\n",
      "    Macro Precision: 0.8670\n",
      "    Macro Recall:    0.8528\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.908 (P=0.891, R=0.925, S=600.0)\n",
      "      Rel_CE      : F1=0.811 (P=0.843, R=0.781, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7585\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 9/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4528\n",
      "  Average Validation Loss:         2.1359\n",
      "  Overall Validation Avg F1 (Macro): 0.7594\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8395\n",
      "    Macro Precision: 0.8474\n",
      "    Macro Recall:    0.8413\n",
      "    Accuracy:        0.8400\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8302 (P=0.9026, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8487 (P=0.7922, R=0.9140, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5782\n",
      "    Macro Precision: 0.5417\n",
      "    Macro Recall:    0.6455\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.513 (P=0.466, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.646 (P=0.670, R=0.624, S=1451.0)\n",
      "      B-E       : F1=0.467 (P=0.434, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.630 (P=0.644, R=0.617, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.472 (P=0.355, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.902, R=0.901, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8604\n",
      "    Macro Precision: 0.8696\n",
      "    Macro Recall:    0.8532\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.909 (P=0.891, R=0.929, S=605.0)\n",
      "      Rel_CE      : F1=0.811 (P=0.849, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7594\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 10/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4420\n",
      "  Average Validation Loss:         2.1431\n",
      "  Overall Validation Avg F1 (Macro): 0.7601\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5775\n",
      "    Macro Precision: 0.5393\n",
      "    Macro Recall:    0.6472\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.506 (P=0.457, R=0.567, S=263.0)\n",
      "      I-C       : F1=0.646 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.469 (P=0.435, R=0.509, S=271.0)\n",
      "      I-E       : F1=0.635 (P=0.642, R=0.627, S=1846.0)\n",
      "      B-CE      : F1=0.409 (P=0.310, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8612\n",
      "    Macro Precision: 0.8708\n",
      "    Macro Recall:    0.8537\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.910 (P=0.890, R=0.930, S=600.0)\n",
      "      Rel_CE      : F1=0.813 (P=0.852, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7601\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 11/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4368\n",
      "  Average Validation Loss:         2.1544\n",
      "  Overall Validation Avg F1 (Macro): 0.7580\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5774\n",
      "    Macro Precision: 0.5394\n",
      "    Macro Recall:    0.6470\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.506 (P=0.457, R=0.567, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.469 (P=0.435, R=0.509, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.626, S=1846.0)\n",
      "      B-CE      : F1=0.409 (P=0.310, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8549\n",
      "    Macro Precision: 0.8619\n",
      "    Macro Recall:    0.8491\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.905 (P=0.890, R=0.921, S=606.0)\n",
      "      Rel_CE      : F1=0.805 (P=0.834, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 1/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 12/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4306\n",
      "  Average Validation Loss:         2.1536\n",
      "  Overall Validation Avg F1 (Macro): 0.7584\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5775\n",
      "    Macro Precision: 0.5396\n",
      "    Macro Recall:    0.6470\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.506 (P=0.457, R=0.567, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.470 (P=0.437, R=0.509, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.626, S=1846.0)\n",
      "      B-CE      : F1=0.409 (P=0.310, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8560\n",
      "    Macro Precision: 0.8635\n",
      "    Macro Recall:    0.8499\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.906 (P=0.890, R=0.922, S=606.0)\n",
      "      Rel_CE      : F1=0.806 (P=0.837, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 2/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 13/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4367\n",
      "  Average Validation Loss:         2.1771\n",
      "  Overall Validation Avg F1 (Macro): 0.7592\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5410\n",
      "    Macro Recall:    0.6470\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.457, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.626, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8571\n",
      "    Macro Precision: 0.8649\n",
      "    Macro Recall:    0.8507\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.907 (P=0.890, R=0.924, S=605.0)\n",
      "      Rel_CE      : F1=0.807 (P=0.840, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 3/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 14/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4339\n",
      "  Average Validation Loss:         2.1345\n",
      "  Overall Validation Avg F1 (Macro): 0.7567\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5410\n",
      "    Macro Recall:    0.6470\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.457, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.626, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8497\n",
      "    Macro Precision: 0.8551\n",
      "    Macro Recall:    0.8452\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.900 (P=0.888, R=0.913, S=597.0)\n",
      "      Rel_CE      : F1=0.799 (P=0.823, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 4/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 15/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4218\n",
      "  Average Validation Loss:         2.1305\n",
      "  Overall Validation Avg F1 (Macro): 0.7568\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8499\n",
      "    Macro Precision: 0.8553\n",
      "    Macro Recall:    0.8453\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.900 (P=0.888, R=0.913, S=599.0)\n",
      "      Rel_CE      : F1=0.799 (P=0.823, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 5/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 16/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4319\n",
      "  Average Validation Loss:         2.1581\n",
      "  Overall Validation Avg F1 (Macro): 0.7589\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8562\n",
      "    Macro Precision: 0.8636\n",
      "    Macro Recall:    0.8501\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.906 (P=0.890, R=0.923, S=608.0)\n",
      "      Rel_CE      : F1=0.806 (P=0.837, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 6/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 17/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4241\n",
      "  Average Validation Loss:         2.1536\n",
      "  Overall Validation Avg F1 (Macro): 0.7555\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.634 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8460\n",
      "    Macro Precision: 0.8500\n",
      "    Macro Recall:    0.8425\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.898 (P=0.889, R=0.908, S=606.0)\n",
      "      Rel_CE      : F1=0.794 (P=0.811, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7601. Patience: 7/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 18/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4316\n",
      "  Average Validation Loss:         2.1404\n",
      "  Overall Validation Avg F1 (Macro): 0.7618\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.633 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8651\n",
      "    Macro Precision: 0.8762\n",
      "    Macro Recall:    0.8566\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.913 (P=0.892, R=0.936, S=607.0)\n",
      "      Rel_CE      : F1=0.817 (P=0.861, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7618\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 19/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4175\n",
      "  Average Validation Loss:         2.1458\n",
      "  Overall Validation Avg F1 (Macro): 0.7603\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.633 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8606\n",
      "    Macro Precision: 0.8698\n",
      "    Macro Recall:    0.8533\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.910 (P=0.891, R=0.929, S=607.0)\n",
      "      Rel_CE      : F1=0.811 (P=0.849, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7618. Patience: 1/20\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 20/20 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4320\n",
      "  Average Validation Loss:         2.1481\n",
      "  Overall Validation Avg F1 (Macro): 0.7569\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.8417\n",
      "    Macro Precision: 0.8501\n",
      "    Macro Recall:    0.8436\n",
      "    Accuracy:        0.8422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.8322 (P=0.9072, R=0.7686, Support=229.0)\n",
      "      causal      : F1=0.8512 (P=0.7930, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.5788\n",
      "    Macro Precision: 0.5412\n",
      "    Macro Recall:    0.6469\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.508 (P=0.459, R=0.570, S=263.0)\n",
      "      I-C       : F1=0.647 (P=0.667, R=0.627, S=1451.0)\n",
      "      B-E       : F1=0.468 (P=0.435, R=0.506, S=271.0)\n",
      "      I-E       : F1=0.633 (P=0.642, R=0.625, S=1846.0)\n",
      "      B-CE      : F1=0.419 (P=0.321, R=0.600, S=15.0)\n",
      "      I-CE      : F1=0.476 (P=0.360, R=0.701, S=77.0)\n",
      "      O         : F1=0.901 (P=0.904, R=0.899, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8504\n",
      "    Macro Precision: 0.8558\n",
      "    Macro Recall:    0.8457\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.901 (P=0.889, R=0.914, S=605.0)\n",
      "      Rel_CE      : F1=0.799 (P=0.823, R=0.777, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7618. Patience: 2/20\n",
      "================================================================================\n",
      "\n",
      "Loading best model state (in memory) with F1: 0.7618\n",
      "Training history saved to /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/training_history.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        device=DEVICE,\n",
    "        id2label_cls=id2label_cls,\n",
    "        id2label_bio=id2label_bio,\n",
    "        id2label_rel=id2label_rel,\n",
    "        model_save_path=model_save_path,\n",
    "        scheduler=scheduler,\n",
    "        cls_class_weights=cls_weights,\n",
    "        bio_class_weights=bio_weights, # Only for softmax\n",
    "        rel_class_weights=rel_weights,\n",
    "        patience_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        seed=SEED,\n",
    "        max_grad_norm=TRAINING_CONFIG[\"gradient_clip_val\"],\n",
    "        eval_fn_metrics=evaluate_model, # Pass your evaluate_model function here\n",
    "        print_report_fn=print_eval_report # Pass your print_eval_report function here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d65306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add8aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax/tokenizer_config.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax/special_tokens_map.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax/vocab.txt',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax/added_tokens.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tokenizer.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_softmax/hf_exper_bert_softmax\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ef916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
