{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnorouzini/JointLearning/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from config import DEVICE, SEED, MODEL_CONFIG, TRAINING_CONFIG, DATASET_CONFIG\n",
    "from model import JointCausalModel\n",
    "from utility import compute_class_weights, label_value_counts\n",
    "from dataset_collator import CausalDataset, CausalDatasetCollator\n",
    "from config import id2label_cls, id2label_bio, id2label_rel\n",
    "from evaluate_joint_causal_model import evaluate_model, print_eval_report\n",
    "from trainer import train_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fec89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/train.csv\"\n",
    "train_data_path = \"/home/rnorouzini/JointLearning/datasets/pseudo_annotate_data/llama3_8b_processed.csv\"\n",
    "val_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/val.csv\"\n",
    "test_data_path = \"/home/rnorouzini/JointLearning/datasets/expert_multi_task_data/test.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caee3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CausalDataset(\n",
    "    train_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "val_dataset = CausalDataset(\n",
    "    val_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%\n",
    "test_dataset = CausalDataset(\n",
    "    test_df,\n",
    "    tokenizer_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    max_length=DATASET_CONFIG[\"max_length\"],\n",
    ")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd2fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_labels_value_counts:\n",
      " 1    75746\n",
      "0    24254\n",
      "Name: count, dtype: int64\n",
      "bio_labels_value_counts:\n",
      "  6      1965606\n",
      " 3       603618\n",
      " 1       556437\n",
      "-100     200000\n",
      " 2        95248\n",
      " 0        95057\n",
      " 5        72190\n",
      " 4        11638\n",
      "Name: count, dtype: int64\n",
      "rel_labels_value_counts:\n",
      " 0    223800\n",
      "1    115514\n",
      "Name: count, dtype: int64\n",
      "CLS Weights: tensor([0.0010, 0.0010])\n",
      "BIO Weights: tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010])\n",
      "REL Weights: tensor([0.0010, 0.0010])\n"
     ]
    }
   ],
   "source": [
    "labels_flat = label_value_counts(train_dataset)\n",
    "# %%\n",
    "cls_label_flat = labels_flat[\"cls_labels_flat\"]\n",
    "bio_label_flat = labels_flat[\"bio_labels_flat\"]\n",
    "rel_label_flat = labels_flat[\"rel_labels_flat\"]\n",
    "# %%\n",
    "# Calculate class weights\n",
    "cls_weights = compute_class_weights(labels_list=cls_label_flat, num_classes=MODEL_CONFIG[\"num_cls_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "bio_weights = compute_class_weights(labels_list=bio_label_flat, num_classes=MODEL_CONFIG[\"num_bio_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "rel_weights = compute_class_weights(labels_list=rel_label_flat, num_classes=MODEL_CONFIG[\"num_rel_labels\"], technique=\"ens\", ignore_index=-100)\n",
    "print(f\"CLS Weights: {cls_weights}\")\n",
    "print(f\"BIO Weights: {bio_weights}\")\n",
    "print(f\"REL Weights: {rel_weights}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98d81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = CausalDatasetCollator(\n",
    "    tokenizer=train_dataset.tokenizer\n",
    ")\n",
    "# %%\n",
    "# take a 100 samples from train_dataset\n",
    "# train_dataset = torch.utils.data.Subset(train_dataset, random.sample(range(len(train_dataset)), 20))\n",
    "# val_dataset = torch.utils.data.Subset(val_dataset, random.sample(range(len(val_dataset)), 20))\n",
    "# # %%\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_CONFIG[\"batch_size\"],\n",
    "    collate_fn=collator,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09250461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JointCausalModel(\n",
    "    encoder_name=MODEL_CONFIG[\"encoder_name\"],\n",
    "    num_cls_labels=MODEL_CONFIG[\"num_cls_labels\"],\n",
    "    num_bio_labels=MODEL_CONFIG[\"num_bio_labels\"],\n",
    "    num_rel_labels=MODEL_CONFIG[\"num_rel_labels\"],\n",
    "    dropout=MODEL_CONFIG[\"dropout\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5a8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=TRAINING_CONFIG[\"learning_rate\"],\n",
    "    weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n",
    ")\n",
    "# %%\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eaed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0df434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Configuration ---\n",
      "Device: cuda\n",
      "Number of Epochs: 10\n",
      "Seed: 8642\n",
      "Optimizer: AdamW (LR: 1e-05, Weight Decay: 0.01)\n",
      "Scheduler: ReduceLROnPlateau\n",
      "Gradient Clipping: Disabled (Max Norm: N/A)\n",
      "Early Stopping Patience: 10\n",
      "Model Save Path: /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt\n",
      "Mode: Silver Data Training (GCE)\n",
      "GCE q value: 0.7\n",
      "Task loss weights not provided, using default: {'cls': 1.0, 'bio': 1.0, 'rel': 1.0}\n",
      "CLS Class Weights: None\n",
      "BIO Class Weights: None\n",
      "REL Class Weights: None\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]:   0%|          | 0/6250 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 1/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.7838\n",
      "  Average Validation Loss:         0.8575\n",
      "  Overall Validation Avg F1 (Macro): 0.6645\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7048\n",
      "    Macro Precision: 0.7881\n",
      "    Macro Recall:    0.7243\n",
      "    Accuracy:        0.7200\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.6379 (P=0.9328, R=0.4847, Support=229.0)\n",
      "      causal      : F1=0.7717 (P=0.6435, R=0.9638, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4028\n",
      "    Macro Precision: 0.3742\n",
      "    Macro Recall:    0.4860\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.340 (P=0.285, R=0.422, S=263.0)\n",
      "      I-C       : F1=0.534 (P=0.430, R=0.703, S=1451.0)\n",
      "      B-E       : F1=0.193 (P=0.268, R=0.151, S=271.0)\n",
      "      I-E       : F1=0.577 (P=0.488, R=0.704, S=1846.0)\n",
      "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
      "      I-CE      : F1=0.336 (P=0.226, R=0.649, S=77.0)\n",
      "      O         : F1=0.841 (P=0.922, R=0.772, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8859\n",
      "    Macro Precision: 0.8842\n",
      "    Macro Recall:    0.8877\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.922 (P=0.927, R=0.917, S=605.0)\n",
      "      Rel_CE      : F1=0.850 (P=0.842, R=0.858, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6645\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 2/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.5903\n",
      "  Average Validation Loss:         0.8662\n",
      "  Overall Validation Avg F1 (Macro): 0.6730\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.6948\n",
      "    Macro Precision: 0.7799\n",
      "    Macro Recall:    0.7154\n",
      "    Accuracy:        0.7111\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.6243 (P=0.9231, R=0.4716, Support=229.0)\n",
      "      causal      : F1=0.7653 (P=0.6366, R=0.9593, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4247\n",
      "    Macro Precision: 0.3816\n",
      "    Macro Recall:    0.5200\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.358 (P=0.307, R=0.430, S=263.0)\n",
      "      I-C       : F1=0.536 (P=0.439, R=0.689, S=1451.0)\n",
      "      B-E       : F1=0.369 (P=0.321, R=0.435, S=271.0)\n",
      "      I-E       : F1=0.578 (P=0.476, R=0.733, S=1846.0)\n",
      "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
      "      I-CE      : F1=0.298 (P=0.198, R=0.597, S=77.0)\n",
      "      O         : F1=0.834 (P=0.930, R=0.755, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.8995\n",
      "    Macro Precision: 0.8969\n",
      "    Macro Recall:    0.9023\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.931 (P=0.938, R=0.924, S=605.0)\n",
      "      Rel_CE      : F1=0.868 (P=0.856, R=0.881, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6730\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 3/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.5097\n",
      "  Average Validation Loss:         0.8110\n",
      "  Overall Validation Avg F1 (Macro): 0.6937\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7315\n",
      "    Macro Precision: 0.7979\n",
      "    Macro Recall:    0.7460\n",
      "    Accuracy:        0.7422\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.6778 (P=0.9313, R=0.5328, Support=229.0)\n",
      "      causal      : F1=0.7852 (P=0.6646, R=0.9593, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4391\n",
      "    Macro Precision: 0.4021\n",
      "    Macro Recall:    0.5226\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.368 (P=0.310, R=0.452, S=263.0)\n",
      "      I-C       : F1=0.542 (P=0.430, R=0.735, S=1451.0)\n",
      "      B-E       : F1=0.362 (P=0.328, R=0.402, S=271.0)\n",
      "      I-E       : F1=0.597 (P=0.510, R=0.722, S=1846.0)\n",
      "      B-CE      : F1=0.083 (P=0.111, R=0.067, S=15.0)\n",
      "      I-CE      : F1=0.284 (P=0.195, R=0.519, S=77.0)\n",
      "      O         : F1=0.838 (P=0.931, R=0.761, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9106\n",
      "    Macro Precision: 0.9115\n",
      "    Macro Recall:    0.9096\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.939 (P=0.937, R=0.942, S=601.0)\n",
      "      Rel_CE      : F1=0.882 (P=0.886, R=0.877, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6937\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 4/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.4508\n",
      "  Average Validation Loss:         0.8106\n",
      "  Overall Validation Avg F1 (Macro): 0.6991\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7495\n",
      "    Macro Precision: 0.7898\n",
      "    Macro Recall:    0.7586\n",
      "    Accuracy:        0.7556\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7105 (P=0.8940, R=0.5895, Support=229.0)\n",
      "      causal      : F1=0.7885 (P=0.6856, R=0.9276, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4378\n",
      "    Macro Precision: 0.3969\n",
      "    Macro Recall:    0.5293\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.388 (P=0.338, R=0.456, S=263.0)\n",
      "      I-C       : F1=0.543 (P=0.456, R=0.673, S=1451.0)\n",
      "      B-E       : F1=0.357 (P=0.326, R=0.395, S=271.0)\n",
      "      I-E       : F1=0.583 (P=0.502, R=0.696, S=1846.0)\n",
      "      B-CE      : F1=0.093 (P=0.071, R=0.133, S=15.0)\n",
      "      I-CE      : F1=0.254 (P=0.164, R=0.571, S=77.0)\n",
      "      O         : F1=0.845 (P=0.922, R=0.781, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9099\n",
      "    Macro Precision: 0.9162\n",
      "    Macro Recall:    0.9044\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.941 (P=0.928, R=0.954, S=608.0)\n",
      "      Rel_CE      : F1=0.879 (P=0.904, R=0.855, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6991\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 5/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3799\n",
      "  Average Validation Loss:         0.7804\n",
      "  Overall Validation Avg F1 (Macro): 0.7048\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7596\n",
      "    Macro Precision: 0.7940\n",
      "    Macro Recall:    0.7672\n",
      "    Accuracy:        0.7644\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7254 (P=0.8917, R=0.6114, Support=229.0)\n",
      "      causal      : F1=0.7938 (P=0.6962, R=0.9231, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4429\n",
      "    Macro Precision: 0.4011\n",
      "    Macro Recall:    0.5309\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.378 (P=0.327, R=0.449, S=263.0)\n",
      "      I-C       : F1=0.551 (P=0.461, R=0.686, S=1451.0)\n",
      "      B-E       : F1=0.365 (P=0.329, R=0.410, S=271.0)\n",
      "      I-E       : F1=0.592 (P=0.515, R=0.696, S=1846.0)\n",
      "      B-CE      : F1=0.100 (P=0.080, R=0.133, S=15.0)\n",
      "      I-CE      : F1=0.266 (P=0.175, R=0.558, S=77.0)\n",
      "      O         : F1=0.847 (P=0.920, R=0.785, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9119\n",
      "    Macro Precision: 0.9147\n",
      "    Macro Recall:    0.9093\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.941 (P=0.935, R=0.948, S=610.0)\n",
      "      Rel_CE      : F1=0.882 (P=0.894, R=0.871, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7048\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 6/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3641\n",
      "  Average Validation Loss:         0.7783\n",
      "  Overall Validation Avg F1 (Macro): 0.7069\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7641\n",
      "    Macro Precision: 0.7989\n",
      "    Macro Recall:    0.7717\n",
      "    Accuracy:        0.7689\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7306 (P=0.8981, R=0.6157, Support=229.0)\n",
      "      causal      : F1=0.7977 (P=0.6997, R=0.9276, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4452\n",
      "    Macro Precision: 0.4035\n",
      "    Macro Recall:    0.5329\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.390 (P=0.341, R=0.456, S=263.0)\n",
      "      I-C       : F1=0.556 (P=0.469, R=0.682, S=1451.0)\n",
      "      B-E       : F1=0.364 (P=0.327, R=0.410, S=271.0)\n",
      "      I-E       : F1=0.585 (P=0.506, R=0.692, S=1846.0)\n",
      "      B-CE      : F1=0.103 (P=0.083, R=0.133, S=15.0)\n",
      "      I-CE      : F1=0.272 (P=0.178, R=0.571, S=77.0)\n",
      "      O         : F1=0.847 (P=0.919, R=0.786, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9115\n",
      "    Macro Precision: 0.9143\n",
      "    Macro Recall:    0.9089\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.941 (P=0.935, R=0.947, S=603.0)\n",
      "      Rel_CE      : F1=0.882 (P=0.894, R=0.871, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7069\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 7/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3543\n",
      "  Average Validation Loss:         0.7863\n",
      "  Overall Validation Avg F1 (Macro): 0.7058\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7550\n",
      "    Macro Precision: 0.7891\n",
      "    Macro Recall:    0.7628\n",
      "    Accuracy:        0.7600\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7202 (P=0.8854, R=0.6070, Support=229.0)\n",
      "      causal      : F1=0.7899 (P=0.6928, R=0.9186, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4463\n",
      "    Macro Precision: 0.4040\n",
      "    Macro Recall:    0.5386\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.379 (P=0.331, R=0.445, S=263.0)\n",
      "      I-C       : F1=0.554 (P=0.464, R=0.689, S=1451.0)\n",
      "      B-E       : F1=0.366 (P=0.336, R=0.402, S=271.0)\n",
      "      I-E       : F1=0.579 (P=0.505, R=0.679, S=1846.0)\n",
      "      B-CE      : F1=0.136 (P=0.103, R=0.200, S=15.0)\n",
      "      I-CE      : F1=0.263 (P=0.171, R=0.571, S=77.0)\n",
      "      O         : F1=0.845 (P=0.918, R=0.784, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9160\n",
      "    Macro Precision: 0.9220\n",
      "    Macro Recall:    0.9108\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.945 (P=0.932, R=0.957, S=606.0)\n",
      "      Rel_CE      : F1=0.887 (P=0.912, R=0.865, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 1/10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 8/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3437\n",
      "  Average Validation Loss:         0.7877\n",
      "  Overall Validation Avg F1 (Macro): 0.7045\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7572\n",
      "    Macro Precision: 0.7925\n",
      "    Macro Recall:    0.7650\n",
      "    Accuracy:        0.7622\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7221 (P=0.8910, R=0.6070, Support=229.0)\n",
      "      causal      : F1=0.7922 (P=0.6939, R=0.9231, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4436\n",
      "    Macro Precision: 0.4011\n",
      "    Macro Recall:    0.5350\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.383 (P=0.331, R=0.452, S=263.0)\n",
      "      I-C       : F1=0.558 (P=0.466, R=0.693, S=1451.0)\n",
      "      B-E       : F1=0.375 (P=0.336, R=0.424, S=271.0)\n",
      "      I-E       : F1=0.583 (P=0.506, R=0.688, S=1846.0)\n",
      "      B-CE      : F1=0.095 (P=0.074, R=0.133, S=15.0)\n",
      "      I-CE      : F1=0.267 (P=0.174, R=0.571, S=77.0)\n",
      "      O         : F1=0.845 (P=0.920, R=0.782, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9127\n",
      "    Macro Precision: 0.9158\n",
      "    Macro Recall:    0.9098\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.942 (P=0.935, R=0.949, S=603.0)\n",
      "      Rel_CE      : F1=0.884 (P=0.897, R=0.871, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 2/10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 9/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3414\n",
      "  Average Validation Loss:         0.7777\n",
      "  Overall Validation Avg F1 (Macro): 0.7045\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7596\n",
      "    Macro Precision: 0.7940\n",
      "    Macro Recall:    0.7672\n",
      "    Accuracy:        0.7644\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7254 (P=0.8917, R=0.6114, Support=229.0)\n",
      "      causal      : F1=0.7938 (P=0.6962, R=0.9231, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4434\n",
      "    Macro Precision: 0.4011\n",
      "    Macro Recall:    0.5341\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.382 (P=0.331, R=0.452, S=263.0)\n",
      "      I-C       : F1=0.557 (P=0.467, R=0.692, S=1451.0)\n",
      "      B-E       : F1=0.374 (P=0.336, R=0.421, S=271.0)\n",
      "      I-E       : F1=0.582 (P=0.505, R=0.687, S=1846.0)\n",
      "      B-CE      : F1=0.098 (P=0.077, R=0.133, S=15.0)\n",
      "      I-CE      : F1=0.266 (P=0.173, R=0.571, S=77.0)\n",
      "      O         : F1=0.845 (P=0.919, R=0.782, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9105\n",
      "    Macro Precision: 0.9129\n",
      "    Macro Recall:    0.9082\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.940 (P=0.935, R=0.945, S=605.0)\n",
      "      Rel_CE      : F1=0.881 (P=0.891, R=0.871, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 3/10\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Epoch 10/10 Summary\n",
      "--------------------------------------------------------------------------------\n",
      "  Average Training Loss:           0.3432\n",
      "  Average Validation Loss:         0.7881\n",
      "  Overall Validation Avg F1 (Macro): 0.7067\n",
      "--------------------------------------------------------------------------------\n",
      "Task-Specific Validation Performance:\n",
      "\n",
      "  [Task 1: Sentence Classification]\n",
      "    Macro F1-Score:  0.7614\n",
      "    Macro Precision: 0.7993\n",
      "    Macro Recall:    0.7696\n",
      "    Accuracy:        0.7667\n",
      "    Per-class details:\n",
      "      non-causal  : F1=0.7258 (P=0.9026, R=0.6070, Support=229.0)\n",
      "      causal      : F1=0.7969 (P=0.6959, R=0.9321, Support=221.0)\n",
      "\n",
      "  [Task 2: BIO Prediction (Token-BIO)]\n",
      "    Macro F1-Score:  0.4492\n",
      "    Macro Precision: 0.4049\n",
      "    Macro Recall:    0.5440\n",
      "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      B-C       : F1=0.378 (P=0.326, R=0.449, S=263.0)\n",
      "      I-C       : F1=0.556 (P=0.464, R=0.694, S=1451.0)\n",
      "      B-E       : F1=0.373 (P=0.335, R=0.421, S=271.0)\n",
      "      I-E       : F1=0.584 (P=0.504, R=0.694, S=1846.0)\n",
      "      B-CE      : F1=0.140 (P=0.107, R=0.200, S=15.0)\n",
      "      I-CE      : F1=0.270 (P=0.177, R=0.571, S=77.0)\n",
      "      O         : F1=0.844 (P=0.921, R=0.780, S=11513.0)\n",
      "\n",
      "  [Task 3: Relation Prediction]\n",
      "    Macro F1-Score:  0.9093\n",
      "    Macro Precision: 0.9100\n",
      "    Macro Recall:    0.9087\n",
      "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
      "      Rel_None    : F1=0.938 (P=0.937, R=0.940, S=600.0)\n",
      "      Rel_CE      : F1=0.880 (P=0.883, R=0.877, S=310.0)\n",
      "--------------------------------------------------------------------------------\n",
      "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 4/10\n",
      "================================================================================\n",
      "\n",
      "Loading best model state (in memory) with F1: 0.7069\n",
      "Training history saved to /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/training_history.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        device=DEVICE,\n",
    "        id2label_cls=id2label_cls,\n",
    "        id2label_bio=id2label_bio,\n",
    "        id2label_rel=id2label_rel,\n",
    "        model_save_path=model_save_path,\n",
    "        scheduler=scheduler,\n",
    "        patience_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "        seed=SEED,\n",
    "        max_grad_norm=TRAINING_CONFIG[\"gradient_clip_val\"],\n",
    "        eval_fn_metrics=evaluate_model, # Pass your evaluate_model function here\n",
    "        print_report_fn=print_eval_report, # Pass your print_eval_report function here\n",
    "        is_silver_training=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e63b34",
   "metadata": {},
   "source": [
    "```\n",
    "--- Training Configuration ---\n",
    "Device: cuda\n",
    "Number of Epochs: 10\n",
    "Seed: 8642\n",
    "Optimizer: AdamW (LR: 1e-05, Weight Decay: 0.01)\n",
    "Scheduler: ReduceLROnPlateau\n",
    "Gradient Clipping: Disabled (Max Norm: N/A)\n",
    "Early Stopping Patience: 10\n",
    "Model Save Path: /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt\n",
    "Mode: Silver Data Training (GCE)\n",
    "GCE q value: 0.7\n",
    "Task loss weights not provided, using default: {'cls': 1.0, 'bio': 1.0, 'rel': 1.0}\n",
    "CLS Class Weights: None\n",
    "BIO Class Weights: None\n",
    "REL Class Weights: None\n",
    "----------------------------\n",
    "Epoch 1/10 [Training]:   0%|          | 0/6250 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 1/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.7838\n",
    "  Average Validation Loss:         0.8575\n",
    "  Overall Validation Avg F1 (Macro): 0.6645\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7048\n",
    "    Macro Precision: 0.7881\n",
    "    Macro Recall:    0.7243\n",
    "    Accuracy:        0.7200\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.6379 (P=0.9328, R=0.4847, Support=229.0)\n",
    "      causal      : F1=0.7717 (P=0.6435, R=0.9638, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4028\n",
    "    Macro Precision: 0.3742\n",
    "    Macro Recall:    0.4860\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.340 (P=0.285, R=0.422, S=263.0)\n",
    "      I-C       : F1=0.534 (P=0.430, R=0.703, S=1451.0)\n",
    "      B-E       : F1=0.193 (P=0.268, R=0.151, S=271.0)\n",
    "      I-E       : F1=0.577 (P=0.488, R=0.704, S=1846.0)\n",
    "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
    "      I-CE      : F1=0.336 (P=0.226, R=0.649, S=77.0)\n",
    "      O         : F1=0.841 (P=0.922, R=0.772, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.8859\n",
    "    Macro Precision: 0.8842\n",
    "    Macro Recall:    0.8877\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.922 (P=0.927, R=0.917, S=605.0)\n",
    "      Rel_CE      : F1=0.850 (P=0.842, R=0.858, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6645\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 2/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.5903\n",
    "  Average Validation Loss:         0.8662\n",
    "  Overall Validation Avg F1 (Macro): 0.6730\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.6948\n",
    "    Macro Precision: 0.7799\n",
    "    Macro Recall:    0.7154\n",
    "    Accuracy:        0.7111\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.6243 (P=0.9231, R=0.4716, Support=229.0)\n",
    "      causal      : F1=0.7653 (P=0.6366, R=0.9593, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4247\n",
    "    Macro Precision: 0.3816\n",
    "    Macro Recall:    0.5200\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.358 (P=0.307, R=0.430, S=263.0)\n",
    "      I-C       : F1=0.536 (P=0.439, R=0.689, S=1451.0)\n",
    "      B-E       : F1=0.369 (P=0.321, R=0.435, S=271.0)\n",
    "      I-E       : F1=0.578 (P=0.476, R=0.733, S=1846.0)\n",
    "      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)\n",
    "      I-CE      : F1=0.298 (P=0.198, R=0.597, S=77.0)\n",
    "      O         : F1=0.834 (P=0.930, R=0.755, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.8995\n",
    "    Macro Precision: 0.8969\n",
    "    Macro Recall:    0.9023\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.931 (P=0.938, R=0.924, S=605.0)\n",
    "      Rel_CE      : F1=0.868 (P=0.856, R=0.881, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6730\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 3/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.5097\n",
    "  Average Validation Loss:         0.8110\n",
    "  Overall Validation Avg F1 (Macro): 0.6937\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7315\n",
    "    Macro Precision: 0.7979\n",
    "    Macro Recall:    0.7460\n",
    "    Accuracy:        0.7422\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.6778 (P=0.9313, R=0.5328, Support=229.0)\n",
    "      causal      : F1=0.7852 (P=0.6646, R=0.9593, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4391\n",
    "    Macro Precision: 0.4021\n",
    "    Macro Recall:    0.5226\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.368 (P=0.310, R=0.452, S=263.0)\n",
    "      I-C       : F1=0.542 (P=0.430, R=0.735, S=1451.0)\n",
    "      B-E       : F1=0.362 (P=0.328, R=0.402, S=271.0)\n",
    "      I-E       : F1=0.597 (P=0.510, R=0.722, S=1846.0)\n",
    "      B-CE      : F1=0.083 (P=0.111, R=0.067, S=15.0)\n",
    "      I-CE      : F1=0.284 (P=0.195, R=0.519, S=77.0)\n",
    "      O         : F1=0.838 (P=0.931, R=0.761, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9106\n",
    "    Macro Precision: 0.9115\n",
    "    Macro Recall:    0.9096\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.939 (P=0.937, R=0.942, S=601.0)\n",
    "      Rel_CE      : F1=0.882 (P=0.886, R=0.877, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6937\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 4/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.4508\n",
    "  Average Validation Loss:         0.8106\n",
    "  Overall Validation Avg F1 (Macro): 0.6991\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7495\n",
    "    Macro Precision: 0.7898\n",
    "    Macro Recall:    0.7586\n",
    "    Accuracy:        0.7556\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7105 (P=0.8940, R=0.5895, Support=229.0)\n",
    "      causal      : F1=0.7885 (P=0.6856, R=0.9276, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4378\n",
    "    Macro Precision: 0.3969\n",
    "    Macro Recall:    0.5293\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.388 (P=0.338, R=0.456, S=263.0)\n",
    "      I-C       : F1=0.543 (P=0.456, R=0.673, S=1451.0)\n",
    "      B-E       : F1=0.357 (P=0.326, R=0.395, S=271.0)\n",
    "      I-E       : F1=0.583 (P=0.502, R=0.696, S=1846.0)\n",
    "      B-CE      : F1=0.093 (P=0.071, R=0.133, S=15.0)\n",
    "      I-CE      : F1=0.254 (P=0.164, R=0.571, S=77.0)\n",
    "      O         : F1=0.845 (P=0.922, R=0.781, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9099\n",
    "    Macro Precision: 0.9162\n",
    "    Macro Recall:    0.9044\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.941 (P=0.928, R=0.954, S=608.0)\n",
    "      Rel_CE      : F1=0.879 (P=0.904, R=0.855, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6991\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 5/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3799\n",
    "  Average Validation Loss:         0.7804\n",
    "  Overall Validation Avg F1 (Macro): 0.7048\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7596\n",
    "    Macro Precision: 0.7940\n",
    "    Macro Recall:    0.7672\n",
    "    Accuracy:        0.7644\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7254 (P=0.8917, R=0.6114, Support=229.0)\n",
    "      causal      : F1=0.7938 (P=0.6962, R=0.9231, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4429\n",
    "    Macro Precision: 0.4011\n",
    "    Macro Recall:    0.5309\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.378 (P=0.327, R=0.449, S=263.0)\n",
    "      I-C       : F1=0.551 (P=0.461, R=0.686, S=1451.0)\n",
    "      B-E       : F1=0.365 (P=0.329, R=0.410, S=271.0)\n",
    "      I-E       : F1=0.592 (P=0.515, R=0.696, S=1846.0)\n",
    "      B-CE      : F1=0.100 (P=0.080, R=0.133, S=15.0)\n",
    "      I-CE      : F1=0.266 (P=0.175, R=0.558, S=77.0)\n",
    "      O         : F1=0.847 (P=0.920, R=0.785, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9119\n",
    "    Macro Precision: 0.9147\n",
    "    Macro Recall:    0.9093\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.941 (P=0.935, R=0.948, S=610.0)\n",
    "      Rel_CE      : F1=0.882 (P=0.894, R=0.871, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7048\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 6/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3641\n",
    "  Average Validation Loss:         0.7783\n",
    "  Overall Validation Avg F1 (Macro): 0.7069\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7641\n",
    "    Macro Precision: 0.7989\n",
    "    Macro Recall:    0.7717\n",
    "    Accuracy:        0.7689\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7306 (P=0.8981, R=0.6157, Support=229.0)\n",
    "      causal      : F1=0.7977 (P=0.6997, R=0.9276, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4452\n",
    "    Macro Precision: 0.4035\n",
    "    Macro Recall:    0.5329\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.390 (P=0.341, R=0.456, S=263.0)\n",
    "      I-C       : F1=0.556 (P=0.469, R=0.682, S=1451.0)\n",
    "      B-E       : F1=0.364 (P=0.327, R=0.410, S=271.0)\n",
    "      I-E       : F1=0.585 (P=0.506, R=0.692, S=1846.0)\n",
    "      B-CE      : F1=0.103 (P=0.083, R=0.133, S=15.0)\n",
    "      I-CE      : F1=0.272 (P=0.178, R=0.571, S=77.0)\n",
    "      O         : F1=0.847 (P=0.919, R=0.786, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9115\n",
    "    Macro Precision: 0.9143\n",
    "    Macro Recall:    0.9089\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.941 (P=0.935, R=0.947, S=603.0)\n",
    "      Rel_CE      : F1=0.882 (P=0.894, R=0.871, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.7069\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 7/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3543\n",
    "  Average Validation Loss:         0.7863\n",
    "  Overall Validation Avg F1 (Macro): 0.7058\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7550\n",
    "    Macro Precision: 0.7891\n",
    "    Macro Recall:    0.7628\n",
    "    Accuracy:        0.7600\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7202 (P=0.8854, R=0.6070, Support=229.0)\n",
    "      causal      : F1=0.7899 (P=0.6928, R=0.9186, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4463\n",
    "    Macro Precision: 0.4040\n",
    "    Macro Recall:    0.5386\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.379 (P=0.331, R=0.445, S=263.0)\n",
    "      I-C       : F1=0.554 (P=0.464, R=0.689, S=1451.0)\n",
    "      B-E       : F1=0.366 (P=0.336, R=0.402, S=271.0)\n",
    "      I-E       : F1=0.579 (P=0.505, R=0.679, S=1846.0)\n",
    "      B-CE      : F1=0.136 (P=0.103, R=0.200, S=15.0)\n",
    "      I-CE      : F1=0.263 (P=0.171, R=0.571, S=77.0)\n",
    "      O         : F1=0.845 (P=0.918, R=0.784, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9160\n",
    "    Macro Precision: 0.9220\n",
    "    Macro Recall:    0.9108\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.945 (P=0.932, R=0.957, S=606.0)\n",
    "      Rel_CE      : F1=0.887 (P=0.912, R=0.865, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 1/10\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 8/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3437\n",
    "  Average Validation Loss:         0.7877\n",
    "  Overall Validation Avg F1 (Macro): 0.7045\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7572\n",
    "    Macro Precision: 0.7925\n",
    "    Macro Recall:    0.7650\n",
    "    Accuracy:        0.7622\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7221 (P=0.8910, R=0.6070, Support=229.0)\n",
    "      causal      : F1=0.7922 (P=0.6939, R=0.9231, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4436\n",
    "    Macro Precision: 0.4011\n",
    "    Macro Recall:    0.5350\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.383 (P=0.331, R=0.452, S=263.0)\n",
    "      I-C       : F1=0.558 (P=0.466, R=0.693, S=1451.0)\n",
    "      B-E       : F1=0.375 (P=0.336, R=0.424, S=271.0)\n",
    "      I-E       : F1=0.583 (P=0.506, R=0.688, S=1846.0)\n",
    "      B-CE      : F1=0.095 (P=0.074, R=0.133, S=15.0)\n",
    "      I-CE      : F1=0.267 (P=0.174, R=0.571, S=77.0)\n",
    "      O         : F1=0.845 (P=0.920, R=0.782, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9127\n",
    "    Macro Precision: 0.9158\n",
    "    Macro Recall:    0.9098\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.942 (P=0.935, R=0.949, S=603.0)\n",
    "      Rel_CE      : F1=0.884 (P=0.897, R=0.871, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 2/10\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                 \n",
    "================================================================================\n",
    "Epoch 9/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3414\n",
    "  Average Validation Loss:         0.7777\n",
    "  Overall Validation Avg F1 (Macro): 0.7045\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7596\n",
    "    Macro Precision: 0.7940\n",
    "    Macro Recall:    0.7672\n",
    "    Accuracy:        0.7644\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7254 (P=0.8917, R=0.6114, Support=229.0)\n",
    "      causal      : F1=0.7938 (P=0.6962, R=0.9231, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4434\n",
    "    Macro Precision: 0.4011\n",
    "    Macro Recall:    0.5341\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.382 (P=0.331, R=0.452, S=263.0)\n",
    "      I-C       : F1=0.557 (P=0.467, R=0.692, S=1451.0)\n",
    "      B-E       : F1=0.374 (P=0.336, R=0.421, S=271.0)\n",
    "      I-E       : F1=0.582 (P=0.505, R=0.687, S=1846.0)\n",
    "      B-CE      : F1=0.098 (P=0.077, R=0.133, S=15.0)\n",
    "      I-CE      : F1=0.266 (P=0.173, R=0.571, S=77.0)\n",
    "      O         : F1=0.845 (P=0.919, R=0.782, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9105\n",
    "    Macro Precision: 0.9129\n",
    "    Macro Recall:    0.9082\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.940 (P=0.935, R=0.945, S=605.0)\n",
    "      Rel_CE      : F1=0.881 (P=0.891, R=0.871, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 3/10\n",
    "================================================================================\n",
    "\n",
    "                                                                                                                                  \n",
    "================================================================================\n",
    "Epoch 10/10 Summary\n",
    "--------------------------------------------------------------------------------\n",
    "  Average Training Loss:           0.3432\n",
    "  Average Validation Loss:         0.7881\n",
    "  Overall Validation Avg F1 (Macro): 0.7067\n",
    "--------------------------------------------------------------------------------\n",
    "Task-Specific Validation Performance:\n",
    "\n",
    "  [Task 1: Sentence Classification]\n",
    "    Macro F1-Score:  0.7614\n",
    "    Macro Precision: 0.7993\n",
    "    Macro Recall:    0.7696\n",
    "    Accuracy:        0.7667\n",
    "    Per-class details:\n",
    "      non-causal  : F1=0.7258 (P=0.9026, R=0.6070, Support=229.0)\n",
    "      causal      : F1=0.7969 (P=0.6959, R=0.9321, Support=221.0)\n",
    "\n",
    "  [Task 2: BIO Prediction (Token-BIO)]\n",
    "    Macro F1-Score:  0.4492\n",
    "    Macro Precision: 0.4049\n",
    "    Macro Recall:    0.5440\n",
    "    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      B-C       : F1=0.378 (P=0.326, R=0.449, S=263.0)\n",
    "      I-C       : F1=0.556 (P=0.464, R=0.694, S=1451.0)\n",
    "      B-E       : F1=0.373 (P=0.335, R=0.421, S=271.0)\n",
    "      I-E       : F1=0.584 (P=0.504, R=0.694, S=1846.0)\n",
    "      B-CE      : F1=0.140 (P=0.107, R=0.200, S=15.0)\n",
    "      I-CE      : F1=0.270 (P=0.177, R=0.571, S=77.0)\n",
    "      O         : F1=0.844 (P=0.921, R=0.780, S=11513.0)\n",
    "\n",
    "  [Task 3: Relation Prediction]\n",
    "    Macro F1-Score:  0.9093\n",
    "    Macro Precision: 0.9100\n",
    "    Macro Recall:    0.9087\n",
    "    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):\n",
    "      Rel_None    : F1=0.938 (P=0.937, R=0.940, S=600.0)\n",
    "      Rel_CE      : F1=0.880 (P=0.883, R=0.877, S=310.0)\n",
    "--------------------------------------------------------------------------------\n",
    "Status: Overall Avg F1 did not improve. Best: 0.7069. Patience: 4/10\n",
    "================================================================================\n",
    "\n",
    "Loading best model state (in memory) with F1: 0.7069\n",
    "Training history saved to /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/training_history.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d65306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add8aeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP/tokenizer_config.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP/special_tokens_map.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP/vocab.txt',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP/added_tokens.json',\n",
       " '/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tokenizer.save_pretrained(\n",
    "    r\"/home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/hf_exper_bert_GCE_weakSP\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ef916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
