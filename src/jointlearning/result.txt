--- Training Configuration ---
Device: cuda
Number of Epochs: 10
Seed: 8642
Optimizer: AdamW (LR: 1e-05, Weight Decay: 0.1)
Scheduler: ReduceLROnPlateau
Max Grad Norm: 1.0 (Mode: L2 norm if enabled)
Early Stopping Patience: 10
Model Save Path: /home/rnorouzini/JointLearning/src/jointlearning/expert_bert_GCE_weakSP/expert_bert_GCE_weakSP_model.pt
Mode: Silver Data Training (GCE)
GCE q value: 0.7
Task loss weights not provided, using default: {'cls': 1.0, 'bio': 1.0, 'rel': 1.0}
CLS Class Weights: None
BIO Class Weights: None
REL Class Weights: None
----------------------------
Epoch 1/10 [Training]:   0%|          | 0/6250 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
                                                                                                                                 
================================================================================
Epoch 1/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.6193
  Average Validation Loss:         1.0684
  Overall Validation Avg F1 (Macro): 0.6124
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.5592
    Macro Precision: 0.7812
    Macro Recall:    0.6245
    Accuracy:        0.6178
    Per-class details:
      non-causal  : F1=0.3986 (P=1.0000, R=0.2489, Support=229.0)
      causal      : F1=0.7199 (P=0.5623, R=1.0000, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3617
    Macro Precision: 0.3310
    Macro Recall:    0.4428
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.342 (P=0.277, R=0.445, S=263.0)
      I-C       : F1=0.511 (P=0.388, R=0.748, S=1451.0)
      B-E       : F1=0.345 (P=0.293, R=0.421, S=271.0)
      I-E       : F1=0.547 (P=0.412, R=0.813, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.786 (P=0.946, R=0.673, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9162
    Macro Precision: 0.9222
    Macro Recall:    0.9109
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.945 (P=0.933, R=0.957, S=610.0)
      Rel_CE      : F1=0.887 (P=0.912, R=0.865, S=310.0)
--------------------------------------------------------------------------------
Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6124
================================================================================

                                                                                                                                 
================================================================================
Epoch 2/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.4703
  Average Validation Loss:         0.9613
  Overall Validation Avg F1 (Macro): 0.6405
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6150
    Macro Precision: 0.7748
    Macro Recall:    0.6592
    Accuracy:        0.6533
    Per-class details:
      non-causal  : F1=0.4935 (P=0.9620, R=0.3319, Support=229.0)
      causal      : F1=0.7365 (P=0.5876, R=0.9864, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3781
    Macro Precision: 0.3430
    Macro Recall:    0.4575
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.361 (P=0.290, R=0.479, S=263.0)
      I-C       : F1=0.529 (P=0.402, R=0.770, S=1451.0)
      B-E       : F1=0.361 (P=0.301, R=0.450, S=271.0)
      I-E       : F1=0.587 (P=0.466, R=0.794, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.809 (P=0.942, R=0.710, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9284
    Macro Precision: 0.9329
    Macro Recall:    0.9244
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.952 (P=0.943, R=0.962, S=601.0)
      Rel_CE      : F1=0.905 (P=0.923, R=0.887, S=310.0)
--------------------------------------------------------------------------------
Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6405
================================================================================

                                                                                                                                 
================================================================================
Epoch 3/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.4094
  Average Validation Loss:         0.9829
  Overall Validation Avg F1 (Macro): 0.6383
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6241
    Macro Precision: 0.7779
    Macro Recall:    0.6657
    Accuracy:        0.6600
    Per-class details:
      non-causal  : F1=0.5080 (P=0.9634, R=0.3450, Support=229.0)
      causal      : F1=0.7402 (P=0.5924, R=0.9864, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3678
    Macro Precision: 0.3327
    Macro Recall:    0.4567
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.363 (P=0.283, R=0.506, S=263.0)
      I-C       : F1=0.511 (P=0.389, R=0.746, S=1451.0)
      B-E       : F1=0.350 (P=0.283, R=0.458, S=271.0)
      I-E       : F1=0.561 (P=0.430, R=0.810, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.789 (P=0.944, R=0.678, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9231
    Macro Precision: 0.9234
    Macro Recall:    0.9228
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.948 (P=0.947, R=0.949, S=605.0)
      Rel_CE      : F1=0.898 (P=0.900, R=0.897, S=310.0)
--------------------------------------------------------------------------------
Status: Overall Avg F1 did not improve. Best: 0.6405. Patience: 1/10
================================================================================

                                                                                                                                 
================================================================================
Epoch 4/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.3630
  Average Validation Loss:         0.9332
  Overall Validation Avg F1 (Macro): 0.6500
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6489
    Macro Precision: 0.7973
    Macro Recall:    0.6855
    Accuracy:        0.6800
    Per-class details:
      non-causal  : F1=0.5443 (P=0.9885, R=0.3755, Support=229.0)
      causal      : F1=0.7534 (P=0.6061, R=0.9955, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3790
    Macro Precision: 0.3428
    Macro Recall:    0.4593
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.382 (P=0.305, R=0.510, S=263.0)
      I-C       : F1=0.521 (P=0.401, R=0.744, S=1451.0)
      B-E       : F1=0.352 (P=0.288, R=0.454, S=271.0)
      I-E       : F1=0.586 (P=0.464, R=0.796, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.811 (P=0.941, R=0.713, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9221
    Macro Precision: 0.9277
    Macro Recall:    0.9171
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.948 (P=0.937, R=0.960, S=601.0)
      Rel_CE      : F1=0.896 (P=0.919, R=0.874, S=310.0)
--------------------------------------------------------------------------------
Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6500
================================================================================

                                                                                                                                 
================================================================================
Epoch 5/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.3070
  Average Validation Loss:         0.9556
  Overall Validation Avg F1 (Macro): 0.6461
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6370
    Macro Precision: 0.7937
    Macro Recall:    0.6768
    Accuracy:        0.6711
    Per-class details:
      non-causal  : F1=0.5256 (P=0.9880, R=0.3581, Support=229.0)
      causal      : F1=0.7483 (P=0.5995, R=0.9955, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3750
    Macro Precision: 0.3392
    Macro Recall:    0.4559
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.383 (P=0.305, R=0.513, S=263.0)
      I-C       : F1=0.520 (P=0.404, R=0.729, S=1451.0)
      B-E       : F1=0.342 (P=0.278, R=0.446, S=271.0)
      I-E       : F1=0.574 (P=0.449, R=0.796, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.806 (P=0.939, R=0.706, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9263
    Macro Precision: 0.9292
    Macro Recall:    0.9237
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.951 (P=0.945, R=0.957, S=605.0)
      Rel_CE      : F1=0.902 (P=0.914, R=0.890, S=310.0)
--------------------------------------------------------------------------------
Status: Overall Avg F1 did not improve. Best: 0.6500. Patience: 1/10
================================================================================

                                                                                                                                 
================================================================================
Epoch 6/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.2952
  Average Validation Loss:         0.9500
  Overall Validation Avg F1 (Macro): 0.6475
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6361
    Macro Precision: 0.7820
    Macro Recall:    0.6744
    Accuracy:        0.6689
    Per-class details:
      non-causal  : F1=0.5270 (P=0.9651, R=0.3624, Support=229.0)
      causal      : F1=0.7453 (P=0.5989, R=0.9864, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3760
    Macro Precision: 0.3402
    Macro Recall:    0.4564
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.378 (P=0.304, R=0.498, S=263.0)
      I-C       : F1=0.519 (P=0.404, R=0.724, S=1451.0)
      B-E       : F1=0.357 (P=0.289, R=0.469, S=271.0)
      I-E       : F1=0.573 (P=0.447, R=0.798, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.806 (P=0.938, R=0.706, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9305
    Macro Precision: 0.9384
    Macro Recall:    0.9238
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.954 (P=0.939, R=0.970, S=602.0)
      Rel_CE      : F1=0.907 (P=0.938, R=0.877, S=310.0)
--------------------------------------------------------------------------------
Status: Overall Avg F1 did not improve. Best: 0.6500. Patience: 2/10
================================================================================

                                                                                                                                 
================================================================================
Epoch 7/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.2886
  Average Validation Loss:         0.9682
  Overall Validation Avg F1 (Macro): 0.6486
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6351
    Macro Precision: 0.7873
    Macro Recall:    0.6745
    Accuracy:        0.6689
    Per-class details:
      non-causal  : F1=0.5240 (P=0.9762, R=0.3581, Support=229.0)
      causal      : F1=0.7462 (P=0.5984, R=0.9910, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3751
    Macro Precision: 0.3394
    Macro Recall:    0.4586
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.372 (P=0.299, R=0.494, S=263.0)
      I-C       : F1=0.527 (P=0.407, R=0.744, S=1451.0)
      B-E       : F1=0.354 (P=0.286, R=0.465, S=271.0)
      I-E       : F1=0.570 (P=0.440, R=0.809, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.802 (P=0.943, R=0.698, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9358
    Macro Precision: 0.9421
    Macro Recall:    0.9303
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.958 (P=0.945, R=0.970, S=606.0)
      Rel_CE      : F1=0.914 (P=0.939, R=0.890, S=310.0)
--------------------------------------------------------------------------------
Status: Overall Avg F1 did not improve. Best: 0.6500. Patience: 3/10
================================================================================

                                                                                                                                 
================================================================================
Epoch 8/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.2800
  Average Validation Loss:         0.9509
  Overall Validation Avg F1 (Macro): 0.6498
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6469
    Macro Precision: 0.7911
    Macro Recall:    0.6832
    Accuracy:        0.6778
    Per-class details:
      non-causal  : F1=0.5426 (P=0.9773, R=0.3755, Support=229.0)
      causal      : F1=0.7513 (P=0.6050, R=0.9910, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3752
    Macro Precision: 0.3395
    Macro Recall:    0.4563
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.371 (P=0.297, R=0.494, S=263.0)
      I-C       : F1=0.523 (P=0.406, R=0.732, S=1451.0)
      B-E       : F1=0.354 (P=0.287, R=0.461, S=271.0)
      I-E       : F1=0.573 (P=0.446, R=0.802, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.806 (P=0.940, R=0.705, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9273
    Macro Precision: 0.9322
    Macro Recall:    0.9229
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.952 (P=0.942, R=0.962, S=605.0)
      Rel_CE      : F1=0.903 (P=0.923, R=0.884, S=310.0)
--------------------------------------------------------------------------------
Status: Overall Avg F1 did not improve. Best: 0.6500. Patience: 4/10
================================================================================

                                                                                                                                 
================================================================================
Epoch 9/10 Summary
--------------------------------------------------------------------------------
  Average Training Loss:           0.2790
  Average Validation Loss:         0.9405
  Overall Validation Avg F1 (Macro): 0.6517
--------------------------------------------------------------------------------
Task-Specific Validation Performance:

  [Task 1: Sentence Classification]
    Macro F1-Score:  0.6499
    Macro Precision: 0.7921
    Macro Recall:    0.6854
    Accuracy:        0.6800
    Per-class details:
      non-causal  : F1=0.5472 (P=0.9775, R=0.3799, Support=229.0)
      causal      : F1=0.7526 (P=0.6066, R=0.9910, Support=221.0)

  [Task 2: BIO Prediction (Token-BIO)]
    Macro F1-Score:  0.3765
    Macro Precision: 0.3406
    Macro Recall:    0.4569
    Per-tag details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      B-C       : F1=0.374 (P=0.300, R=0.498, S=263.0)
      I-C       : F1=0.522 (P=0.407, R=0.728, S=1451.0)
      B-E       : F1=0.357 (P=0.290, R=0.465, S=271.0)
      I-E       : F1=0.574 (P=0.449, R=0.798, S=1846.0)
      B-CE      : F1=0.000 (P=0.000, R=0.000, S=15.0)
      I-CE      : F1=0.000 (P=0.000, R=0.000, S=77.0)
      O         : F1=0.807 (P=0.939, R=0.708, S=11513.0)

  [Task 3: Relation Prediction]
    Macro F1-Score:  0.9287
    Macro Precision: 0.9332
    Macro Recall:    0.9246
    Per-relation type details (P=Precision, R=Recall, F1=F1-Score, S=Support):
      Rel_None    : F1=0.953 (P=0.944, R=0.962, S=608.0)
      Rel_CE      : F1=0.905 (P=0.923, R=0.887, S=310.0)
--------------------------------------------------------------------------------
Status: ðŸŽ‰ New best model saved! Overall Avg F1: 0.6517
================================================================================

Epoch 10/10 [Training]:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2942/6250 [04:19<04:40, 11.80it/s, bio=0.1263, cls=0.0000, rel=0.0123, total_loss=0.1386]